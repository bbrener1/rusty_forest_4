{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations\n",
    "\n",
    "In this notebook we wish to run a simulation demonstrating some of the basic claims we make regarding the random \n",
    "forest. \n",
    "\n",
    "The key claims we would like to demonstrate are thus:\n",
    "\n",
    "- A dataset can have heirarchal behavior\n",
    "    - an RF will identify such hierarchal structure \n",
    "    - an RF will capture local changes in covariance etc\n",
    "    \n",
    "    - A PCA CANNOT capture some of the effects that we will identify as local in distinct PCs.\n",
    "\n",
    "- When a dataset undergoes changes in population prevalence, we identify this as a shift in factor values\n",
    "\n",
    "- When a dataset undergoes a change in population behavior we identify this as a shift in predictive power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reflect a hierarchal structure with meaningful local behavior, we will need several features that have different means among different clusters, but importantly also interact with each other. In order to approximately reflect the behavior of single-cell data we will draw from a mixture of multi-dimensional gaussians with known covariance and then randomly sample over the draw as per poisson. \n",
    "\n",
    "Let's operate on 10 features total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal,norm,beta\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we generate the macro-structure. \n",
    "\n",
    "# We will produce a simple pattern with 5 features with a mean and covariance, 3 features with only a mean, \n",
    "# and two features of pure noise\n",
    "\n",
    "macro_cov = np.array(\n",
    "    [\n",
    "        [1, 0, 1, 0, 2, 0, 0, 0, 0, 0],\n",
    "        [0, 1,-1, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 2, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 3, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# We want a positive semi-definite (or definite) matrix\n",
    "macro_cov = np.dot(macro_cov,macro_cov.T)\n",
    "\n",
    "\n",
    "\n",
    "macro_mean_1 = [\n",
    "                    2,3,1,1,0, \n",
    "                    0,1,2, \n",
    "                    3,3\n",
    "]\n",
    "\n",
    "macro_mean_2 = [\n",
    "                    0,-1,1,0,0, \n",
    "                    -3,2,2, \n",
    "                    3,3\n",
    "]\n",
    "\n",
    "macro_mean_3 = [\n",
    "                    0,-1,1,0,0, \n",
    "                    -3,0,4, \n",
    "                    1,3\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_samples_1 = multivariate_normal(macro_mean_1,macro_cov).rvs(1000)\n",
    "macro_samples_2 = multivariate_normal(macro_mean_2,macro_cov).rvs(1500)\n",
    "macro_samples_3 = multivariate_normal(macro_mean_3,macro_cov).rvs(500)\n",
    "\n",
    "coordinates = np.vstack([macro_samples_1,macro_samples_2,macro_samples_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_coordinates = TSNE().fit_transform(coordinates)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(*t_coordinates.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To introduce a local effect, we would like to use a similar but not identical covariance matrix for a smaller part of the dataset\n",
    "\n",
    "micro_cov_1 = np.array(\n",
    "    [\n",
    "        [1, 0, 1, 0, 2, 0, 0, 2, 0, 0],\n",
    "        [0, 1,-1, 0, 0, 0, 0, 0, 3, 0],\n",
    "        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 2, 0, 0, 0, 2, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 1, 2, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 2, 1, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 1, 2, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 3, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "micro_cov_1 = np.dot(micro_cov_1,micro_cov_1.T)\n",
    "\n",
    "micro_cov_2 = np.array(\n",
    "    [\n",
    "        [1, 0, 1, 0, 2, 0, 0,-1, 0, 0],\n",
    "        [0, 1,-1, 0, 0, 0, 0, 0, 3, 0],\n",
    "        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 2, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 1, 2, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 2, 1, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 1,-1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 2, 2, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 3, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "micro_cov_2 = np.dot(micro_cov_2,micro_cov_2.T)\n",
    "\n",
    "micro_samples_1 = multivariate_normal(macro_mean_1,macro_cov).rvs(1000)\n",
    "micro_samples_2 = multivariate_normal(macro_mean_2,micro_cov_1).rvs(1500)\n",
    "micro_samples_3 = multivariate_normal(macro_mean_3,micro_cov_2).rvs(500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = np.vstack([micro_samples_1,micro_samples_2,micro_samples_3])\n",
    "\n",
    "t_coordinates = TSNE().fit_transform(coordinates)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(*t_coordinates.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.zeros(3000)\n",
    "colors[:1000] = 1\n",
    "colors[1000:2500] = 2\n",
    "colors[-500:] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.scatter(*t_coordinates.T,c=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import tree_reader as tr \n",
    "import lumberjack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = lumberjack.fit(\n",
    "    coordinates,\n",
    "    trees=300,\n",
    "    ifs=5,\n",
    "    ofs=5,\n",
    "    braids=1,\n",
    "    ss=200,\n",
    "    leaves=10,\n",
    "    depth=3,\n",
    "    norm='l1',\n",
    "    sfr=0,\n",
    "    reduce_input='true',\n",
    "    reduce_output='true',\n",
    "#     reduce_input='false',\n",
    "#     reduce_output='false'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.tsne_coordinates = t_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.interpret_splits(mode='additive_mean',metric='euclidean',pca=0,k=200,depth=2,relatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.maximum_spanning_tree(mode='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forest.html_tree_summary(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On The Basis of Component Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import multivariate_normal,norm,beta\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will generate the macro-structure. We will generate an eigenvector that applies globally, has a \n",
    "# multivariate normal set of loadings and a bimodal normal distribution of values\n",
    "\n",
    "global_noise = [\n",
    "    1,1,1,1,1,\n",
    "    1,1,1,\n",
    "    1,1,\n",
    "]\n",
    "\n",
    "loading_means_global = [\n",
    "        1,0,-2,3,5,\n",
    "        0,0,2,\n",
    "        3,3\n",
    "    ]\n",
    "    \n",
    "true_factor_scores = np.zeros((10000,3))\n",
    "    \n",
    "noise = multivariate_normal(global_noise,np.identity(10)/10).rvs(10000)    \n",
    "loadings = multivariate_normal(loading_means_global,np.identity(10)/3).rvs(10000)\n",
    "# loadings = np.tile(loading_means_global,(3000,1))\n",
    "\n",
    "score_draws = norm().rvs(10000) / 3\n",
    "# score_draws = np.zeros(10000)\n",
    "\n",
    "score_draws[:3000] += 2\n",
    "score_draws[3000:] += 5\n",
    "\n",
    "# score_draws = beta(.5,.5).rvs(3000)\n",
    "\n",
    "true_factor_scores[:,0] = score_draws\n",
    "\n",
    "coordinates = (loadings * np.tile(true_factor_scores[:,0],(10,1)).T) + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.imshow(coordinates,aspect='auto',interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_loading_means_1 = [\n",
    "    0,2,0,0,0,\n",
    "    1,3,1,\n",
    "    0,2,\n",
    "]\n",
    "\n",
    "local_loading_means_2 = [\n",
    "    0,-2,0,-2,0,\n",
    "    1,3,3,\n",
    "    3,0,\n",
    "]\n",
    "\n",
    "local_loadings_1 = multivariate_normal(local_loading_means_1,np.identity(10)/10).rvs(5000)\n",
    "local_loadings_2 = multivariate_normal(local_loading_means_2,np.identity(10)/10).rvs(2000)\n",
    "# local_loadings_1 = np.tile(local_loading_means_1,(5000,1))\n",
    "# local_loadings_2 = np.tile(local_loading_means_2,(2000,1))\n",
    "\n",
    "# true_factor_scores[3000:8000,1] = norm().rvs(5000) + 1\n",
    "# true_factor_scores[8000:,2] = norm().rvs(2000) + 1\n",
    "\n",
    "true_factor_scores[3000:8000,1] = np.array(sorted((beta(.1,.1).rvs(5000) * 3 ) + 3))\n",
    "true_factor_scores[8000:,2] = np.array(sorted((beta(.3,.3).rvs(2000) * 3 ) + 3))\n",
    "\n",
    "# true_factor_scores[3000:8000,1] = beta(.5,.5).rvs(5000) \n",
    "# true_factor_scores[8000:,2] = beta(.5,.5).rvs(2000)\n",
    "\n",
    "\n",
    "local_coordinates_1 = np.tile(true_factor_scores[3000:8000,1],(10,1)).T * local_loadings_1\n",
    "local_coordinates_2 = np.tile(true_factor_scores[8000:,2],(10,1)).T * local_loadings_2\n",
    "\n",
    "coordinates[3000:8000] += local_coordinates_1\n",
    "coordinates[8000:] += local_coordinates_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_loadings_1\n",
    "# coordinates = scale(coordinates,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "\n",
    "# sample_agglomeration = dendrogram(linkage(coordinates, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(coordinates,aspect='auto',interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(true_factor_scores,aspect='auto',interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(coordinates[sample_agglomeration],aspect='auto',interpolation='none')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_factor_scores[2995:3005]\n",
    "true_factor_scores[7995:8005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_coordinates = TSNE().fit_transform(coordinates)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(*t_coordinates.T)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"True Factor 1 Scores\")\n",
    "plt.scatter(*t_coordinates.T,c=true_factor_scores[:,0],cmap='bwr')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"True Factor 2 Scores\")\n",
    "plt.scatter(*t_coordinates.T,c=true_factor_scores[:,1],cmap='bwr',vmin=3,vmax=6)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"True Factor 3 Scores\")\n",
    "plt.scatter(*t_coordinates.T,c=true_factor_scores[:,2],cmap='bwr',vmin=3,vmax=6)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = PCA().fit(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct = model.transform(coordinates)\n",
    "pct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"PC1 Scores\")\n",
    "plt.scatter(*t_coordinates.T,c=pct[:,0],cmap='bwr')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"PC2 Scores\")\n",
    "plt.scatter(*t_coordinates.T,c=pct[:,1],cmap='bwr')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"PC3 Scores\")\n",
    "plt.scatter(*t_coordinates.T,c=pct[:,2],cmap='bwr')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"PC4 Scores\")\n",
    "plt.scatter(*t_coordinates.T,c=pct[:,3],cmap='bwr')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(true_factor_scores[:,1],pct[:,2])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(true_factor_scores[:,1],pct[:,3])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(true_factor_scores[:,2],pct[:,2])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(true_factor_scores[:,2],pct[:,3])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import tree_reader as tr \n",
    "import lumberjack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = lumberjack.fit(\n",
    "    coordinates,\n",
    "    trees=300,\n",
    "    ifs=8,\n",
    "    ofs=8,\n",
    "    braids=1,\n",
    "    ss=1000,\n",
    "    leaves=10,\n",
    "    depth=4,\n",
    "    norm='l1',\n",
    "    sfr=0,\n",
    "    reduce_input='true',\n",
    "    reduce_output='true',\n",
    "#     reduce_input='false',\n",
    "#     reduce_output='false',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.tsne_coordinates = t_coordinates\n",
    "forest.reset_split_clusters()\n",
    "forest.interpret_splits(mode='additive_mean',metric='cosine',depth=4,pca=3,k=500,relatives=True)\n",
    "forest.maximum_spanning_tree(mode='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forest.html_tree_summary(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
