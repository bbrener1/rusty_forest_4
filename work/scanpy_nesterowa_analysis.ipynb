{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook will go through a conventional scanpy analysis of citeseq data, so that we can compare it to an \n",
    "# analysis performed by a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nesterowa data comes pre-normalized (I don't want to go digging for the unnormalized counts for now)\n",
    "\n",
    "data_location = '/Users/bbrener1/taylor/raw_data/nesterowa/'\n",
    "\n",
    "nesterowa = sc.read(data_location+'nesterowa_counts.txt')\n",
    "header = np.loadtxt(data_location+'nesterowa_gene_header.txt',dtype=str)\n",
    "# cell_type_matrix = np.loadtxt('nesterowa_cell_type_membership.txt').astype(dtype=bool)\n",
    "# cell_type_header = np.loadtxt('nesterowa_cell_type_header.txt',dtype=str)\n",
    "nesterowa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It also does not need to be transposed or filtered in its current form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.hist(np.sum(forest.output,axis=1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/localscratch/bbrener1/rusty_forest_v3/src')\n",
    "sys.path.append('../src')\n",
    "import tree_reader as tr \n",
    "import lumberjack\n",
    "\n",
    "forest = lumberjack.fit(\n",
    "    np.array(nesterowa.X),\n",
    "    header=header,\n",
    "    trees=100,\n",
    "    braids=1,\n",
    "    ifs=1000,\n",
    "    ofs=1000,\n",
    "    ss=500,\n",
    "    depth=8,\n",
    "    leaves=100,\n",
    "    sfr=.5,\n",
    "    norm='l1',\n",
    "    reduce_input='true',\n",
    ")\n",
    "\n",
    "\n",
    "forest.set_cache(True)\n",
    "# forest.backup(\"scanpy_cmp_nesterowa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/localscratch/bbrener1/rusty_forest_v3/src')\n",
    "# sys.path.append('../src')\n",
    "import tree_reader as tr \n",
    "import lumberjack\n",
    "\n",
    "forest = tr.Forest.reconstitute('scanpy_cmp_nesterowa')\n",
    "forest.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.reset_sample_clusters()\n",
    "# forest.cluster_samples_encoding(sub=.8,k=10,depth=8,metric='jaccard')\n",
    "# forest.cluster_samples_encoding(sub=.5,k=20,depth=8,metric='cosine',pca=100)\n",
    "\n",
    "# forest.reset_leaf_clusters()\n",
    "# forest.cluster_leaves_samples(sub=.5,k=20,depth=6,metric=\"jaccard\")\n",
    "# forest.cluster_leaves_samples(sub=.8,k=20,metric=\"cosine\",pca=100)\n",
    "# forest.cluster_leaves_predictions(sub=.8,k=20,metric=\"cosine\",pca=100,mode=\"mean\")\n",
    "# forest.cluster_samples_leaf_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest.tsne(pca=100)\n",
    "forest.plot_sample_clusters()\n",
    "# forest.trees[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for cluster in forest.leaf_clusters:\n",
    "#     cluster.plot_sample_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.reset_split_clusters()\n",
    "forest.interpret_splits(\n",
    "    relatives=True,\n",
    "    pca=100,\n",
    "    depth=6,\n",
    "    mode='additive_mean',\n",
    "    metric='cosine',\n",
    "    k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(forest.split_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forest.tsne_coordinates = nesterowa.obsm[\"X_umap\"]\n",
    "# forest.tsne(pca=100)\n",
    "# forest.most_likely_tree(depth=6,mode='sample')\n",
    "forest.maximum_spanning_tree(depth=6,mode='samples')\n",
    "forest.html_tree_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now establish the neighbor graph because several methods rely on it\n",
    "\n",
    "sc.pp.neighbors(nesterowa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(nesterowa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(nesterowa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to do clusterin via Louvain as one of the gold standards\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sc.tl.louvain(nesterowa,resolution=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(nesterowa,color='louvain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.tsne(nesterowa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.tsne(nesterowa,color='louvain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.scatter(*citeseq_scaled.obsm['X_tsne'].T,c=forest.sample_labels,s=4,cmap='rainbow')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(*nesterowa.obsm['X_umap'].T,c=forest.sample_labels,s=4,cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.tsne_coordinates = nesterowa.obsm['X_umap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest.plot_sample_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.reset_split_clusters()\n",
    "forest.interpret_splits(mode='additive_mean',depth=5,sub=.5,k=20,metric='cosine',relatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_cluster in forest.split_clusters:\n",
    "    split_cluster.html_sister_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.maximum_spanning_tree(depth=5)\n",
    "# forest.most_likely_tree(depth=5)\n",
    "forest.html_tree_summary(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(forest.nodes(root=True,depth=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marker Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have annotations of cell type based on fluorescence values for these cells, currently one-hot encoded:\n",
    "print(cell_type_header)\n",
    "print(cell_type_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many overlaps in broad peaks?\n",
    "\n",
    "print(np.sum(np.sum(cell_type_matrix[:,:11].astype(dtype=int),axis=1) > 1))\n",
    "\n",
    "# How many no-calls?\n",
    "\n",
    "print(np.sum(np.sum(cell_type_matrix[:,:11].astype(dtype=int),axis=1) < 1))\n",
    "\n",
    "# How many overlaps in narrow peaks? \n",
    "\n",
    "print(np.sum(np.sum(cell_type_matrix[:,11:].astype(dtype=int),axis=1) > 1))\n",
    "\n",
    "# How many no-calls?\n",
    "\n",
    "print(np.sum(np.sum(cell_type_matrix[:,11:].astype(dtype=int),axis=1) < 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,cell_type in enumerate(cell_type_header):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.title(cell_type)\n",
    "    plt.scatter(*nesterowa.obsm['X_tsne'].T,c=cell_type_matrix[:,i],s=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Finding consensus calls may not be deeply informative regardless, so let's try this:\n",
    "\n",
    "louvain_sort = np.argsort(nesterowa.obs['louvain'])\n",
    "forest_sort = np.argsort(forest.sample_labels)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Cell Types Vs Louvain\")\n",
    "plt.imshow(cell_type_matrix[louvain_sort][:,:11],aspect='auto',interpolation='none')\n",
    "plt.set_xticklabels(cell_type_header[:11])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Cell Types Vs Forest\")\n",
    "plt.imshow(cell_type_matrix[forest_sort][:,:11],aspect='auto',interpolation='none')\n",
    "plt.getset_xticklabels(cell_type_header[:11])\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(cell_type_matrix[louvain_sort][:,11:],aspect='auto',interpolation='none')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(cell_type_matrix[forest_sort][:,:11:],aspect='auto',interpolation='none')\n",
    "# plt.show()\n",
    "\n",
    "# Comparisons: Paired membership\n",
    "\n",
    "# Cluster set 1 vs Cluster set 2, % of pairings conserved \n",
    "\n",
    "# Homogeneity, Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Nesterowa Data it appears difficult to separate:\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we wish to examine the behavior of distributions within clusters as defined by louvain and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umi_means = np.array(np.mean(umis,axis=0)).ravel()\n",
    "umi_vars = np.array(np.var(umis,axis=0)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umi_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"UMI Mean vs Variance per feature, Log/Log\")\n",
    "plt.scatter(np.log(umi_means),np.log(umi_vars),s=1)\n",
    "plt.plot([-8,4],[-8,4],c='red')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"UMI Mean vs Variance per feature, Linear\")\n",
    "plt.scatter(umi_means,umi_vars,s=1)\n",
    "plt.plot([0,10],[0,10],c='red')\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,10)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"UMI Mean vs Variance per feature, Linear, low range\")\n",
    "plt.scatter(umi_means,umi_vars,s=1)\n",
    "plt.plot([0,1],[0,1],c='red')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"UMI Mean/Variance Ratio per feature, Linear\")\n",
    "plt.scatter(np.arange(umi_means.shape[0]),(umi_means/umi_vars)[np.argsort(umi_means)],s=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cluster in set(johnston_working.obs['louvain']):\n",
    "    mask = johnston_working.obs['louvain'] == cluster\n",
    "    filtered_cells = np.array(umis[mask])\n",
    "    cluster_means = np.mean(filtered_cells,axis=0)\n",
    "    cluster_var = np.var(filtered_cells,axis=0)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(np.log(cluster_means),np.log(cluster_var),s=1)\n",
    "    plt.plot([-8,4],[-8,4],c='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we wish to examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cluster in set(forest.sample_labels):\n",
    "    mask = forest.sample_labels == cluster\n",
    "    filtered_cells = np.array(umis[mask])\n",
    "    cluster_means = np.mean(filtered_cells,axis=0)\n",
    "    cluster_var = np.var(filtered_cells,axis=0)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title(f\"Cluster:{cluster}\")\n",
    "    plt.scatter(np.log(cluster_means),np.log(cluster_var),s=1)\n",
    "    plt.plot([-8,4],[-8,4],c='red')\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title(f\"UMI Mean/Variance Ratio per feature, Cluster:{cluster}\")\n",
    "    plt.scatter(np.arange(cluster_means.shape[0]),(cluster_means/cluster_var)[np.argsort(cluster_means)],s=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.argsort(np.mean(umis.X,axis=0))[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest,poisson,nbinom\n",
    "\n",
    "def poisson_ks_check(x):\n",
    "    mean = np.mean(x)\n",
    "    cdf = lambda x: poisson.cdf(x,mean)\n",
    "    return kstest(x,cdf)\n",
    "\n",
    "# Correctly fitting a negative binomial is a pain, here is a hacked out version for now:\n",
    "def nb_pr_estimation(x):\n",
    "    mean = np.mean(x)\n",
    "    var = np.var(x)\n",
    "    counter = mean/var\n",
    "        \n",
    "    p = -1 * (counter - 1)\n",
    "    r = mean * ((1-p)/p)\n",
    "        \n",
    "    return p,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_draws = nbinom.rvs(4,.5,size=1000)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(nb_draws)\n",
    "plt.show()\n",
    "\n",
    "nb_pr_estimation(nb_draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks_values = [poisson_ks_check(x)[0] for x in forest.output.T]\n",
    "print(ks_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Kolomogorov-Smirnov Test Statistic Vs ML Estimated Poisson Distribution vs Mean, Global\")\n",
    "plt.scatter(umi_means,ks_values[:2000],s=1)\n",
    "plt.xlabel(\"Mean\")\n",
    "plt.ylabel(\"K-S Statistic\")\n",
    "plt.xlim(0,40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cluster in set(forest.sample_labels):\n",
    "    mask = forest.sample_labels == cluster\n",
    "    filtered_cells = np.array(umis[mask])\n",
    "\n",
    "    ks_values = [poisson_ks_check(x)[0] for x in filtered_cells.T]\n",
    "    means = np.mean(filtered_cells,axis=0)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(f\"Kolomogorov-Smirnov Test Statistic Vs ML Estimated Poisson Distribution vs Mean, Cluster {cluster}\")\n",
    "    plt.scatter(means,ks_values[:2000],s=1)\n",
    "    plt.xlabel(\"Mean\")\n",
    "    plt.ylabel(\"K-S Statistic\")\n",
    "    plt.xlim(0,30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cluster in set(forest.sample_labels):\n",
    "    mask = forest.sample_labels == cluster\n",
    "    filtered_cells = np.array(umis[mask])\n",
    "\n",
    "    size_factors = np.sum(filtered_cells,axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(f\"Size factor distributions, Cluster {cluster}\")\n",
    "    plt.hist(np.array(size_factors),log=True,bins=np.arange(0,50000,200))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_factors = np.array(np.sum(np.array(umis),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(size_factors,bins=np.arange(0,50000,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering/Partition Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score,silhouette_score,silhouette_samples,mutual_info_score,adjusted_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calinski_harabasz_score(cell_type_matrix,nesterowa.obs['louvain']))\n",
    "print(calinski_harabasz_score(cell_type_matrix,forest.sample_labels))\n",
    "\n",
    "print(calinski_harabasz_score(nesterowa.X,nesterowa.obs['louvain']))\n",
    "print(calinski_harabasz_score(nesterowa.X,forest.sample_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(silhouette_score(cell_type_matrix,nesterowa.obs['louvain']))\n",
    "print(silhouette_score(cell_type_matrix,forest.sample_labels))\n",
    "\n",
    "print(silhouette_score(nesterowa.X,nesterowa.obs['louvain'],metric='cosine'))\n",
    "print(silhouette_score(nesterowa.X,forest.sample_labels,metric='cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mutual_info_score(nesterowa.obs['louvain'],forest.sample_labels))\n",
    "print(adjusted_mutual_info_score(nesterowa.obs['louvain'],forest.sample_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Discovery Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.split_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram,linkage\n",
    "\n",
    "feature_sort = dendrogram(linkage(forest.output.T,metric='correlation',method='average'),no_plot=True)['leaves']\n",
    "sample_sort = dendrogram(linkage(forest.output,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(forest.output[sample_sort].T[feature_sort].T,aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Agglomerated Dataset\")\n",
    "plt.imshow(forest.output[np.argsort(forest.sample_labels)].T[feature_sort].T,aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cluster in forest.split_clusters:\n",
    "    factor = cluster.sister_scores()\n",
    "    factor_sort = np.argsort(factor)\n",
    "    print(factor)\n",
    "    print(factor_sort)\n",
    "    plt.figure()\n",
    "    plt.axes([0,0,.8,1])\n",
    "    plt.title(\"Agglomerated Dataset\")\n",
    "    plt.imshow(forest.output[factor_sort].T[feature_sort].T,aspect='auto')\n",
    "    plt.axes([.9,0,.1,1])\n",
    "    plt.imshow(np.array([factor,]).T[factor_sort],cmap='bwr',aspect='auto')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in forest.split_clusters:\n",
    "    factor = cluster.sister_scores()\n",
    "    plt.figure()\n",
    "    plt.axes([0,0,.8,1])\n",
    "    plt.title(\"Agglomerated Dataset\")\n",
    "    plt.imshow(forest.output[sample_sort].T[feature_sort].T,aspect='auto')\n",
    "    plt.axes([.9,0,.1,1])\n",
    "    plt.imshow(np.array([factor,]).T[sample_sort],cmap='bwr',aspect='auto')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = np.corrcoef(forest.output.T)\n",
    "correlations = correlations[feature_sort].T[feature_sort]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Correlations of Features In Nestorowa\")\n",
    "plt.imshow(correlations,cmap='seismic',vmin=-1,vmax=1)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cluster in forest.split_clusters:\n",
    "    factor = cluster.sister_scores()\n",
    "    factor_correlations = np.corrcoef(forest.output.T,factor)[-1,:-1]\n",
    "    plt.figure()\n",
    "    plt.axes([0,0,.8,1])\n",
    "    plt.title(\"Agglomerated Dataset\")\n",
    "    plt.imshow(correlations,cmap='seismic',aspect='auto',vmin=-1,vmax=1)\n",
    "    plt.axes([.9,0,.1,1])\n",
    "    plt.imshow(np.array([factor_correlations[feature_sort],]).T,cmap='seismic',aspect='auto',vmin=-1,vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sister_correlation_matrix = np.zeros((len(forest.split_clusters),len(forest.output_features)))\n",
    "\n",
    "for i,cluster in enumerate(forest.split_clusters):\n",
    "    factor = cluster.sister_scores()\n",
    "    factor_correlations = np.corrcoef(forest.output.T,factor)[-1,:-1]\n",
    "    sister_correlation_matrix[i] = factor_correlations\n",
    "    \n",
    "plt.figure(figsize=(14.2,10))\n",
    "plt.axes([0,0,.7,1])\n",
    "plt.title(\"Agglomerated Dataset\")\n",
    "plt.imshow(correlations,cmap='seismic',aspect='auto',vmin=-1,vmax=1)\n",
    "plt.axes([.8,0,.2,1])\n",
    "plt.imshow(sister_correlation_matrix.T[feature_sort],interpolation='none',cmap='seismic',aspect='auto',vmin=-1,vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
