{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOTE TO SELF ######\n",
    "# Linear behavior global vs braid\n",
    "\n",
    "# SPC25 IS GOOD EXAMPLE\n",
    "# Cenpe good\n",
    "# Mgst3 maybe\n",
    "# Irf8 maybe\n",
    "# Ctsg is marginal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# mpl.rcParams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# COLOR = 'white'\n",
    "# mpl.rcParams['text.color'] = COLOR\n",
    "# mpl.rcParams['axes.labelcolor'] = COLOR\n",
    "# mpl.rcParams['xtick.color'] = COLOR\n",
    "# mpl.rcParams['ytick.color'] = COLOR\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "\n",
    "# import fancyimpute as fi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import variation\n",
    "from math import isnan\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram,linkage\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import lumberjack\n",
    "import tree_reader as tr\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Forest Generation](#forest_generation)\n",
    "* [Prediction Error Analysis](#prediction_error)\n",
    "* [Sample Clustering](#sample_clustering)\n",
    "* [Split Clustering](#split_clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest Generation <a class=\"anchor\" id=\"forest_generation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counts = np.loadtxt('/Users/boris/taylor/johnston_retina/single_cell/dmel-retina-scRNA/exploration/2018.07.19_Scanpy/log_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/johnston_retina/single_cell/dmel-retina-scRNA/exploration/2018.07.19_Scanpy/header.txt\",dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/work/johnston_log_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/work/johnston_header.txt\",dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/aging_sc/var_filtered_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/aging_sc/var_filtered_header.txt\",dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/fan_tendon/log_counts.txt')\n",
    "# header = np.loadtxt(\"/Users/boris/taylor/fan_tendon/header.txt\",dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/bbrener1/taylor/raw_data/nesterowa/nesterowa_counts.txt')\n",
    "# header = np.loadtxt('/Users/bbrener1/taylor/raw_data/nesterowa/nesterowa_gene_header.txt',dtype=str)\n",
    "\n",
    "raw_counts = np.loadtxt('nesterowa_counts.txt')\n",
    "raw_header = np.loadtxt('nesterowa_gene_header.txt',dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/nelmari/nc_filtered_log.txt')\n",
    "# header = np.loadtxt('/Users/boris/taylor/nelmari/gene_header_filtered.txt',dtype=str)\n",
    "\n",
    "# counts = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/testing/iris.trunc')\n",
    "# header = np.loadtxt('/Users/boris/taylor/vision/rust_prototype/rusty_lumberjack/testing/iris.features',dtype=str)\n",
    "\n",
    "# raw_counts = np.loadtxt('./citeseq_cbmc_counts.tsv')\n",
    "# raw_header = np.loadtxt('./citeseq_cbmc_header.txt',dtype=str)\n",
    "\n",
    "# raw_counts = np.loadtxt('./citeseq_cbmc_umis.tsv'')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "feature_sort = dendrogram(linkage(raw_counts.T,metric='correlation',method='average'),no_plot=True)['leaves']\n",
    "cell_sort = dendrogram(linkage(raw_counts,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# feature_sort = np.arange(raw_counts.shape[1])\n",
    "# cell_sort = np.arange(raw_counts.shape[0])\n",
    "\n",
    "counts = raw_counts[cell_sort].T[feature_sort].T\n",
    "counts = raw_counts.T[feature_sort].T\n",
    "header = raw_header[feature_sort]\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title(\"Cell x Gene Expression Unsorted\",fontsize=20)\n",
    "plt.imshow(counts,aspect='auto',cmap=\"bwr\")\n",
    "plt.xlabel(\"Genes\",fontsize=15)\n",
    "plt.ylabel(\"Cells\",fontsize=15)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title(\"Cell x Gene Expression, Agglomerative\",fontsize=20)\n",
    "plt.imshow(counts[cell_sort],aspect='auto',cmap=\"bwr\")\n",
    "plt.xlabel(\"Genes\",fontsize=15)\n",
    "plt.ylabel(\"Cells\",fontsize=15)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Frequency of Mean Gene Expression Values\")\n",
    "plt.xlabel(\"Mean Expression (log TPM)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.hist(np.mean(counts,axis=0),bins=50,log=True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Frequency of Individual Expression Values\")\n",
    "plt.xlabel(\"Mean Expression (log TPM)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.hist(counts.flatten(),bins=50,log=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(np.mean(counts,axis=0).shape)\n",
    "print(header.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"../prediction/\"\n",
    "# raw_text_out = open(output_directory + str(\"evaluation.txt\"),mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_mask = np.random.random(counts.shape[0]) > .1\n",
    "testing_mask = np.logical_not(training_mask)\n",
    "\n",
    "training_counts = counts[training_mask]\n",
    "testing_counts = counts[testing_mask]\n",
    "\n",
    "# training_counts = counts \n",
    "# testing_counts = counts\n",
    "\n",
    "\n",
    "# counts = sklearn.preprocessing.scale(counts)\n",
    "\n",
    "forest = lumberjack.fit(\n",
    "    training_counts,\n",
    "    header=header,\n",
    "    test_counts=testing_counts,\n",
    "    trees=100,\n",
    "    dispersion_mode=\"ssme\",\n",
    "    norm=\"l1\",\n",
    "    drop='none',\n",
    "    sfr=0.5,\n",
    "    in_feature_subsample=2000,\n",
    "    out_feature_subsample=2000,\n",
    "    sample_subsample=400,\n",
    "    depth=8,\n",
    "    leaves=50,\n",
    ")\n",
    "\n",
    "\n",
    "training_counts = forest.output\n",
    "testing_counts = forest.test\n",
    "\n",
    "true_counts = testing_counts\n",
    "\n",
    "subsampling = 1\n",
    "\n",
    "# mask = np.loadtxt('./testing/holdout_mask_counts.txt')\n",
    "\n",
    "# held_out_counts = np.loadtxt('./testing/held_out_counts.txt')\n",
    "\n",
    "#2 trees at 2:17\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.weigh_leaves()\n",
    "predicted = forest.predict_matrix(testing_counts,weighted=False)\n",
    "\n",
    "# nodes = forest.predict_vector_nodes(forest.output[600])\n",
    "# len(nodes)\n",
    "\n",
    "# for sample in forest.output:\n",
    "#     forest.predict_vector_leaves(sample)\n",
    "\n",
    "# nodes[1].filter.reduction.features\n",
    "# for node in nodes:\n",
    "#     print(600 in node.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sort = dendrogram(linkage(true_counts,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "plt.figure()\n",
    "plt.imshow(predicted[test_sort],aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(true_counts[test_sort],aspect='auto')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forest = tr.Forest.reconstitute('./forest_nelmari')\n",
    "\n",
    "forest = tr.Forest.reconstitute('./forest_vision')\n",
    "# forest = tr.Forest.reconstitute('./forest_vision_lrg_l1')\n",
    "# forest = tr.Forest.reconstitute('./forest_vision_lrg_l2')\n",
    "\n",
    "\n",
    "# forest = tr.Forest.reconstitute('./forest_johnston_braid')\n",
    "\n",
    "# forest = tr.Forest.load(\"../testing/nelmari/\",input='../../../../../nelmari/nc_filtered_log.txt',output='../../../../../nelmari/nc_filtered_log.txt')\n",
    "# forest = tr.Forest.load(\"../testing/nesterowa_forest/\",input=\"../../work/nesterowa_counts.txt\",output=\"../../work/nesterowa_counts.txt\")\n",
    "# forest = tr.Forest.load(\"../testing/johnston_forest/\",input=\"../../work/johnston_log_counts.txt\",output=\"../../work/johnston_log_counts.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.backup('./forest_johnston_ihmm')\n",
    "# forest.backup('./forest_johnston_ssme')\n",
    "# forest.backup('./forest_johnston_flat_sme')\n",
    "# forest.backup('./forest_johnston_var')\n",
    "# forest.backup('./forest_fan_ssme')\n",
    "\n",
    "# forest.backup('./forest_johnston_braid')\n",
    "\n",
    "# forest.backup('./forest_nelmari')\n",
    "\n",
    "forest.backup('./forest_vision')\n",
    "# forest.backup('./forest_vision_small')\n",
    "# forest.backup('./forest_vision_l1')\n",
    "# forest.backup('./forest_vision_l2')\n",
    "# forest.backup('./forest_vision_lrg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional adjustment to truncate lower-expressing genes.\n",
    "# expression_level_mask = np.mean(true_counts,axis=0) > 1\n",
    "# true_counts = true_counts.T[expression_level_mask].T\n",
    "# predicted = predicted.T[expression_level_mask].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# raw_text_out.write(\"=================================================\\n\")\n",
    "# raw_text_out.write(\"Basic evaluation: \\n\")\n",
    "\n",
    "# raw_text_out.write(\"Pearson R\\n\")\n",
    "# raw_text_out.write(str(pearsonr(predicted.flatten(),true_counts.flatten())) + \"\\n\")\n",
    "\n",
    "# raw_text_out.write(\"MSE\\n\")\n",
    "# raw_text_out.write(str(np.mean((predicted.flatten() - true_counts.flatten()) ** 2)) + \"\\n\")\n",
    "\n",
    "# raw_text_out.write(\"MAE\\n\")\n",
    "# raw_text_out.write(str(np.mean(np.abs(predicted.flatten() - true_counts.flatten()))) + \"\\n\")\n",
    "\n",
    "\n",
    "# raw_text_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_counts = forest.test\n",
    "\n",
    "# prediction = forest.predict_matrix(test_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sys.path.append(\"/Users/boris/haxx/python/smooth_density_graph/\")\n",
    "# import smooth_density_graph as sdg\n",
    "\n",
    "# forest.reset_clusters()\n",
    "# from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "\n",
    "# feature_sort = dendrogram(linkage(counts.T,metric='correlation',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# counts = forest.output\n",
    "\n",
    "encoding = forest.node_sample_encoding(forest.leaves())\n",
    "# print(encoding.shape)\n",
    "\n",
    "# print(np.sum(np.sum(encoding,axis=1) == 0))\n",
    "cell_encoding_sort = dendrogram(linkage(encoding,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "leaf_sort = dendrogram(linkage(encoding.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# feature_sort = dendrogram(linkage(forest.output.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# feature_sort = np.argsort(np.var(forest.output,axis=0))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "# plt.imshow(encoding,aspect='auto',cmap='binary')\n",
    "plt.imshow(encoding[cell_encoding_sort].T[leaf_sort].T,aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # print(np.sum(np.isnan(encoding).flatten()))\n",
    "\n",
    "# cell_clusterings = forest.cluster_samples_encoding(distance='cos',k=10,steps=50,override=False,verbose=True)\n",
    "# # cell_clusterings = forest.cluster_samples_simple(pca=True,subsample=1400,distance='cos',k=10,steps=50,override=True,verbose=True)\n",
    "# leaf_clusterings = forest.cluster_leaf_samples(distance='cos',k=10,steps=50,override=False,verbose=True)\n",
    "\n",
    "# cell_order = np.argsort(cell_clusterings)\n",
    "# leaf_order = np.argsort(leaf_clusterings)\n",
    "\n",
    "# # clustered_counts = forest.output[cell_order].T[feature_sort].T\n",
    "# clustered_counts = counts[cell_order].T[feature_sort].T\n",
    "# clustered_encoding = encoding[cell_order].T[leaf_order].T\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Cell x Gene Expression, Forest Clustering\",fontsize=20)\n",
    "# plt.imshow(clustered_counts,aspect='auto')\n",
    "# plt.xlabel(\"Genes\",fontsize=15)\n",
    "# plt.ylabel(\"Cells\",fontsize=15)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Cell x Node Organization, Forest Clustering\",fontsize=20)\n",
    "# plt.imshow(clustered_encoding,aspect='auto',cmap='binary')\n",
    "# plt.xlabel(\"Leaves\",fontsize=15)\n",
    "# plt.ylabel(\"Cells\",fontsize=15)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"===================\")\n",
    "\n",
    "# for cluster in forest.sample_clusters:\n",
    "#     print(len(cluster.samples))\n",
    "\n",
    "# print(\"===================\")\n",
    "\n",
    "# for cluster in forest.leaf_clusters:\n",
    "#     print(len(cluster.nodes))\n",
    "\n",
    "# print(\"===================\")\n",
    "# print(\"===================\")\n",
    "# print(\"===================\")\n",
    "# print(len(forest.sample_clusters))\n",
    "# print(len(forest.leaf_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# from scipy.spatial.distance import squareform,pdist\n",
    "\n",
    "# total_encoding = forest.node_sample_encoding(forest.nodes())\n",
    "\n",
    "# total_cell_sort = dendrogram(linkage(total_encoding,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# node_sort = dendrogram(linkage(total_encoding.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(total_encoding[total_cell_sort].T[node_sort].T,aspect='auto',cmap='binary')\n",
    "# plt.show()\n",
    "\n",
    "# sister_encoding = forest.node_sister_encoding(forest.nodes(depth=4))\n",
    "\n",
    "# sister_sort = dendrogram(linkage(sister_encoding.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "\n",
    "# distance_matrix = squareform(pdist(sister_encoding.T,metric='jaccard'))\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(distance_matrix[sister_sort].T[sister_sort],aspect='auto')\n",
    "# plt.show()\n",
    "\n",
    "# distance_sort = dendrogram(linkage(distance_matrix,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(distance_matrix[distance_sort].T[distance_sort],aspect='auto')\n",
    "# plt.show()\n",
    "\n",
    "# total_encoding = forest.node_sample_encoding(forest.nodes())\n",
    "\n",
    "# tc = TSNE(metric='jaccard').fit_transform(total_encoding.T)\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.scatter(tc[:,0],tc[:,1],s=.5)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Clustering <a class=\"anchor\" id=\"split_clustering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest.reset_clusters()\n",
    "forest.interpret_splits(depth=5,sub=.5,k=20,mode='additive_mean',relatives=True,distance='cos',pca=100,override=True)\n",
    "# forest.interpret_splits(depth=5,k=10,subsample=5500,mode='gain',steps=50,distance='cos',override=False,verbose=True)\n",
    "# split_order = np.argsort(forest.split_labels)\n",
    "# print(np.sum(forest.split_labels < 7))\n",
    "# print(np.sum(forest.split_labels < 8))\n",
    "# print(np.sum(forest.split_labels < 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = forest.most_likely_tree(depth=5)\n",
    "tree\n",
    "\n",
    "# tree = forest.maximum_spanning_tree(depth=4)\n",
    "# tree\n",
    "\n",
    "# transitions = forest.split_cluster_transition_matrix()\n",
    "# transitions[:,88]\n",
    "\n",
    "# forest.likely_tree = forest.maximum_tree\n",
    "\n",
    "tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.html_tree_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# forest.coordinates(override=False)\n",
    "# forest.tsne_encoding(override=True)\n",
    "# forest.plot_split_clusters()\n",
    "\n",
    "# feature = \"Cd34\"\n",
    "# coordinates = forest.coordinates(override=False,no_plot=True,pca=True)\n",
    "# fi = forest.truth_dictionary.feature_dictionary[feature]\n",
    "# plt.figure()\n",
    "# plt.title(f\"Expression of {feature}\")\n",
    "# plt.scatter(coordinates[:,0],coordinates[:,1],c=forest.output[:,fi],s=10)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Clustering <a class=\"anchor\" id=\"sample_clustering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.tsne(pca=100,override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# forest.reset_sample_clusters()\n",
    "# forest.cluster_samples_encoding(sub=.5,k=20,metric='cosine',pca=50,override=True)\n",
    "# forest.cluster_samples_simple(pca=True,k=20,steps=50,override=True,verbose=True)\n",
    "forest.plot_sample_clusters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tc = forest.coordinates(no_plot=True)\n",
    "\n",
    "for split_cluster in forest.split_clusters:\n",
    "    print(split_cluster.id)\n",
    "    try:\n",
    "        print(sorted(list(split_cluster.braid_features().items()),key=lambda x:x[1])[::-1])\n",
    "#         print(list(split_cluster.braid_features().items()))\n",
    "    except:\n",
    "        pass\n",
    "    split_cluster.plot_cell_counts()\n",
    "\n",
    "    sister_color = split_cluster.sister_scores()\n",
    "\n",
    "    f = plt.figure(figsize=(15,10))\n",
    "    plt.title(\"Sister Split\")\n",
    "    plt.scatter(tc[:,0],tc[:,1],c=sister_color,cmap='bwr',vmin=max(sister_color)*-1)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cluster_matrix = np.zeros((len(forest.sample_clusters),len(forest.leaf_clusters)))\n",
    "# for i,sample_cluster in enumerate(forest.sample_clusters):\n",
    "#     leaf_cluster_frequency = sample_cluster.leaf_cluster_frequency(plot=False)[1]\n",
    "#     for j,lcf in enumerate(leaf_cluster_frequency):\n",
    "#         cluster_matrix[i,j] = lcf\n",
    "        \n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.title(\"Occurrence of Leaf Clusters in Cell Clusters\",fontsize=30)\n",
    "# plt.imshow(np.log(cluster_matrix+1),aspect='auto')\n",
    "# plt.xlabel(\"Leaf Clusters\",fontsize=24)\n",
    "# plt.ylabel(\"Cell Clusters\",fontsize=24)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# vertical_order = dendrogram(linkage(cluster_matrix,metric='correlation'),no_plot=True)['leaves']\n",
    "# horizontal_order = dendrogram(linkage(cluster_matrix.T,metric='correlation'),no_plot=True)['leaves']\n",
    "\n",
    "# rearranged_sample_ticks = np.arange(len(forest.sample_clusters))[vertical_order]\n",
    "# rearranged_leaf_ticks = np.arange(len(forest.leaf_clusters))[horizontal_order]\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.title(\"Occurrence of Leaf Clusters in Cell Clusters\",fontsize=30)\n",
    "# plt.imshow(np.log(cluster_matrix+1)[vertical_order].T[horizontal_order].T,aspect='auto')\n",
    "# plt.xlabel(\"Leaf Clusters\",fontsize=24)\n",
    "# plt.ylabel(\"Cell Clusters\",fontsize=24)\n",
    "# plt.xticks(np.arange(len(rearranged_leaf_ticks)),rearranged_leaf_ticks)\n",
    "# plt.yticks(np.arange(len(rearranged_sample_ticks)),rearranged_sample_ticks)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Louvain Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import kneighbors_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performed per instructions suggested in python-louvain\n",
    "plt.figure()\n",
    "sg = kneighbors_graph(counts,metric='cosine',n_neighbors=5)\n",
    "g = nx.from_scipy_sparse_matrix(sg)\n",
    "partition = community.best_partition(g,resolution=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = float(len(set(partition.values())))\n",
    "pos = nx.spring_layout(g)\n",
    "count = 0.\n",
    "for com in set(partition.values()) :\n",
    "    count = count + 1.\n",
    "    list_nodes = [nodes for nodes in partition.keys()\n",
    "                                if partition[nodes] == com]\n",
    "    nx.draw_networkx_nodes(g, pos, list_nodes, node_size = 20,\n",
    "                                node_color = str(count / size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_raw_labels = [partition[i] for i in range(len(forest.samples))]\n",
    "set(louvain_raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = community.induced_graph(partition,g)\n",
    "ig_pos = nx.spring_layout(ig)\n",
    "nx.draw_networkx_nodes(ig, ig_pos)\n",
    "nx.draw_networkx_edges(ig, ig_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(forest.coordinates(no_plot=True)[:,0],forest.coordinates(no_plot=True)[:,1],c=louvain_raw_labels,cmap='rainbow',s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now let's try training Louvain on the forest leaf sample encoding:\n",
    "\n",
    "plt.figure()\n",
    "sg = kneighbors_graph(forest.node_sample_encoding(forest.leaves()),metric='jaccard',n_neighbors=5)\n",
    "g = nx.from_scipy_sparse_matrix(sg)\n",
    "partition = community.best_partition(g,resolution=.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = float(len(set(partition.values())))\n",
    "pos = nx.spring_layout(g)\n",
    "count = 0.\n",
    "for com in set(partition.values()) :\n",
    "    count = count + 1.\n",
    "    list_nodes = [nodes for nodes in partition.keys()\n",
    "                                if partition[nodes] == com]\n",
    "    nx.draw_networkx_nodes(g, pos, list_nodes, node_size = 20,\n",
    "                                node_color = str(count / size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_forest_labels = [partition[i] for i in range(len(forest.samples))]\n",
    "set(louvain_raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(forest.coordinates(no_plot=True)[:,0],forest.coordinates(no_plot=True)[:,1],c=louvain_forest_labels,cmap='rainbow',s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.cluster import DBSCAN\n",
    "# from hdbscan import HDBSCAN\n",
    "\n",
    "# encoding = forest.node_sample_encoding(forest.leaves())\n",
    "\n",
    "# d_cell_clusters = HDBSCAN(min_samples=5).fit_predict(encoding)\n",
    "# d_leaf_clusters = HDBSCAN(min_samples=5).fit_predict(encoding.T)\n",
    "\n",
    "# d_cell_ordering = np.argsort(d_cell_clusters)\n",
    "# d_leaf_ordering = np.argsort(d_leaf_clusters)\n",
    "# # d_leaf_ordering = dendrogram(linkage(encoding.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20,8))\n",
    "# plt.imshow(encoding[d_cell_ordering].T[d_leaf_ordering].T,aspect='auto',cmap='binary')\n",
    "# plt.show()\n",
    "\n",
    "# gain_matrix = forest.local_gain_matrix(forest.nodes())\n",
    "\n",
    "# d_leaf_clusters = HDBSCAN(min_samples=5).fit_predict(gain_matrix.T)\n",
    "# d_leaf_ordering = np.argsort(d_leaf_clusters)\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(gain_matrix[feature_sort].T[d_leaf_ordering],aspect='auto',)\n",
    "# plt.show()\n",
    "\n",
    "# print(set(d_cell_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_p_cell_clusters = HDBSCAN(min_samples=5).fit_predict(training_counts)\n",
    "# d_p_feature_clusters = HDBSCAN(min_samples=5).fit_predict(training_counts.T)\n",
    "\n",
    "# d_p_cell_ordering = np.argsort(d_p_cell_clusters)\n",
    "# # d_p_feature_ordering = np.argsort(d_p_feature_clusters)\n",
    "\n",
    "# plt.figure(figsize=(20,8))\n",
    "# plt.imshow(training_counts[d_p_cell_ordering],aspect='auto',cmap='binary')\n",
    "# plt.show()\n",
    "\n",
    "# print(set(d_p_cell_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# k_cell_clusters = KMeans(n_clusters=10).fit_predict(counts)\n",
    "\n",
    "# k_cell_ordering = np.argsort(k_cell_clusters)\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Cell x Gene Expression, K-Means\",fontsize=20)\n",
    "# plt.imshow(counts[k_cell_ordering],aspect='auto')\n",
    "# plt.xlabel(\"Genes\",fontsize=15)\n",
    "# plt.ylabel(\"Cells\",fontsize=15)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Prediction Error <a class=\"anchor\" id=\"prediction_error\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_counts = forest.test\n",
    "# prediction = forest.predict_matrix(test_counts)\n",
    "prediction_features = prediction[:,:4290]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Distribution of Values in Test Counts\")\n",
    "plt.hist(test_counts.flatten(),bins=50,log=True)\n",
    "plt.ylim(0,1e6)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Distribution of Values in Prediction\")\n",
    "plt.hist(prediction.flatten(),bins=50,log=True)\n",
    "plt.ylim(0,1e6)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Distribution of Error\")\n",
    "plt.hist((test_counts - prediction_features).flatten(),bins=50,log=True)\n",
    "plt.ylim(0,1e6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.node_sample_encoding(forest.leaves())\n",
    "# forest.leaves()[3].samples\n",
    "# forest.trees[3].plot()\n",
    "# forest.trees[3].tree_movie('./tree_movies/m1/pr1')\n",
    "# forest.trees[4].tree_movie('./tree_movies/m2/pr1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zero_mask = counts == 0\n",
    "zero_sum = np.sum(zero_mask,axis=0)\n",
    "zero_percentrage = zero_sum / counts.shape[0]\n",
    "\n",
    "plt.figure(\"sparsity_graph\",figsize=(15,10))\n",
    "plt.title(\"Sparsity of Features\",fontsize=20)\n",
    "plt.hist(zero_percentrage,bins=np.arange(0,1.05,0.05))\n",
    "plt.xlabel(\"Sparsity (Fraction of values = 0)\",fontsize=15)\n",
    "plt.ylabel(\"Frequency\",fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_mask = np.random.rand(*test_counts.flatten().shape) < (subsampling/10)\n",
    "\n",
    "plt.figure(\"general_scatter\")\n",
    "plt.title(\"True Expression vs Predicted Expression\")\n",
    "plt.scatter(test_counts.flatten()[random_mask],prediction_features.flatten()[random_mask],s=1,alpha=.3)\n",
    "plt.xlabel(\"True Expression\")\n",
    "plt.ylabel(\"Predicted Expression\")\n",
    "plt.savefig(output_directory+\"general_scatter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(\"mae_vs_mean\",figsize=(20,4))\n",
    "plt.title(\"Mean Absolute Error of Feature Predictions vs Mean Feature Value\")\n",
    "plt.scatter(np.mean(test_counts,axis=0),np.mean(np.abs(test_counts - prediction_features), axis=0),s=.1)\n",
    "plt.plot([0,4],[0,4],c='r')\n",
    "plt.xlabel(\"Mean Gene Expression\")\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.ylim((0,4))\n",
    "plt.savefig(output_directory+\"mae_vs_mean.png\")\n",
    "\n",
    "# Calculate MAE\n",
    "mae = np.mean(np.abs(test_counts - np.tile(np.mean(test_counts,axis=0),(test_counts.shape[0],1))), axis=0)\n",
    "\n",
    "plt.figure(\"mean_abs_dev_vs_mean\",figsize=(20,4))\n",
    "plt.title(\"Mean Absolute Deviation of Features vs Expression Level\")\n",
    "plt.scatter(np.mean(test_counts,axis=0),mae,s=.1)\n",
    "plt.plot([0,4],[0,4],c='r')\n",
    "plt.xlabel(\"Mean Gene Expression\")\n",
    "plt.ylabel(\"Mean Absolute Deviation\")\n",
    "plt.ylim((0,4))\n",
    "plt.savefig(output_directory+\"mean_abs_dev_vs_mean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_mask = np.random.rand(*true_counts.flatten().shape) < subsampling\n",
    "\n",
    "plt.figure(\"bimodal_scatter_by_mean\",figsize=(6,4))\n",
    "plt.title(\"Observed Expressions Vs Mean Expression of Feature\")\n",
    "plt.scatter(np.tile(np.mean(true_counts,axis=0),(true_counts.shape[0],1)).flatten()[random_mask],true_counts.flatten()[random_mask],s=.1,alpha=.1, label=\"Observed Expression\")\n",
    "# plt.scatter(np.mean(true_counts,axis=0),np.median(true_counts,axis=0),c='r',s=.5, label=\"Mean Expression\")\n",
    "plt.xlabel(\"Mean Expression\")\n",
    "plt.ylabel(\"Observed Expression\")\n",
    "plt.xlim(0,4)\n",
    "plt.legend()\n",
    "plt.savefig(output_directory+\"bimodal_scatter_by_mean.png\")\n",
    "\n",
    "for cluster in forest.sample_clusters:\n",
    "    cluster_samples = cluster.samples\n",
    "    cluster_counts = forest.output[cluster_samples]\n",
    "    mean_expression = np.mean(cluster_counts,axis=0)\n",
    "    print(cluster_counts.shape)\n",
    "    plt.figure()\n",
    "    plt.scatter(np.tile(mean_expression,(cluster_counts.shape[0],1)).flatten(),cluster_counts.flatten(),s=.1,alpha=.1)\n",
    "    plt.xlim(0,4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print true_counts[:10,:10]\n",
    "\n",
    "random_mask = np.random.rand(*test_counts.flatten().shape) < subsampling\n",
    "\n",
    "plt.figure(\"bimodal_scatter_by_mean_predicted\",figsize=(20,4))\n",
    "plt.title(\"Predicted Values Vs Observed Means\")\n",
    "plt.scatter(np.tile(np.mean(test_counts,axis=0),(test_counts.shape[0],1)).flatten()[random_mask],prediction_features.flatten()[random_mask],s=.5,alpha=1,label=\"Expression\")\n",
    "plt.scatter(np.mean(test_counts,axis=0),np.median(test_counts,axis=0),c='m',s=1,label=\"Medians\")\n",
    "plt.scatter(np.mean(test_counts,axis=0),np.mean(test_counts,axis=0),c='c',s=1,label=\"Means\")\n",
    "plt.xlim(0,3)\n",
    "plt.legend()\n",
    "plt.savefig(output_directory+\"bimodal_scatter_by_mean_predicted.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_mask = np.random.rand(*test_counts.flatten().shape) < subsampling\n",
    "\n",
    "plt.figure(\"error_scatter_by_mean\", figsize=(20,4))\n",
    "plt.title(\"Observed Error vs Observed Mean of Feature\")\n",
    "plt.scatter(np.tile(np.mean(test_counts,axis=0),(test_counts.shape[0],1)).flatten()[random_mask],(test_counts - prediction_features).flatten()[random_mask],alpha=.3,s=.3)\n",
    "plt.xlabel(\"Mean Expression\")\n",
    "plt.ylabel(\"Predicted Expression\")\n",
    "plt.savefig(output_directory+\"error_scatter_by_mean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"mean_error_vs_mean\",figsize=(20,4))\n",
    "plt.title(\"Mean Absolute Error Vs Mean Expression of Gene\")\n",
    "plt.scatter(np.mean(test_counts,axis=0),np.mean(np.abs(test_counts-prediction_features),axis=0),s=.5,c=np.std(test_counts,axis=0))\n",
    "plt.colorbar(label=\"Standard Deviation of Feature\")\n",
    "# plt.plot([0,3],[0,3])\n",
    "plt.ylim((0,4))\n",
    "plt.xlabel(\"Mean Expression\")\n",
    "plt.ylabel(\"Mean Error\")\n",
    "plt.savefig(output_directory+\"mean_error_vs_mean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"mean_error_vs_std\",figsize=(4,4))\n",
    "plt.title(\"Mean Absolute Error Vs Standard Deviation of Gene Expression\")\n",
    "plt.scatter(np.std(test_counts,axis=0),np.mean(np.abs(test_counts-prediction_features),axis=0),s=.1)\n",
    "# plt.colorbar(label=\"Standard Deviation of Feature\")\n",
    "plt.plot([0,4],[0,4])\n",
    "plt.ylim((0,4))\n",
    "plt.xlim((0,4))\n",
    "plt.xlabel(\"Standard Deviation\")\n",
    "plt.ylabel(\"Mean Error\")\n",
    "plt.savefig(output_directory+\"mean_error_vs_std.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "\n",
    "correlations = []\n",
    "\n",
    "for i in range(test_counts.shape[1]):\n",
    "#     print(test_counts[:,i])\n",
    "#     print(prediction[:,i])\n",
    "#     print(pearsonr(test_counts[:,i],prediction[:,i]))\n",
    "    correlations.append(pearsonr(test_counts[:,i],prediction_features[:,i])[0])\n",
    "    if np.isnan(correlations[-1]):\n",
    "        correlations[-1] = 0\n",
    "        \n",
    "\n",
    "print(len(correlations))\n",
    "\n",
    "plt.figure(\"correlation_vs_mean\",figsize=(20,4))\n",
    "plt.title(\"Correlation of Predictions to Features per Feature\")\n",
    "plt.scatter(np.mean(test_counts,axis=0),correlations,s=.3,c=np.std(test_counts,axis=0))\n",
    "plt.colorbar(label=\"Standard Deviation of Feature\")\n",
    "plt.xlabel(\"Mean Expression\")\n",
    "plt.ylabel(\"Prediction Correlation\")\n",
    "plt.savefig(output_directory+\"correlation_vs_mean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import linregress\n",
    "\n",
    "x = np.std(true_counts,axis=0)\n",
    "y = np.mean(true_counts-prediction_features,axis=0)\n",
    "\n",
    "# slope, intercept, rvalue, pvalue, std_err = linregress(x, y=y)\n",
    "\n",
    "plt.figure(\"mean_error_vs_variance\")\n",
    "plt.title(\"Standard Deviation vs Mean Error\")\n",
    "plt.scatter(x,y,s=.1)\n",
    "# plt.plot(x,x*slope + intercept, 'r', label = str(np.around(rvalue,decimals=3)))\n",
    "plt.plot([0,3],[0,3])\n",
    "plt.plot([0,3],[0,-3])\n",
    "plt.ylim((-1,1))\n",
    "plt.xlabel(\"Standard Deviation\")\n",
    "plt.ylabel(\"Mean Error\")\n",
    "plt.legend()\n",
    "plt.savefig(output_directory+\"mean_error_vs_variance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = []\n",
    "\n",
    "for i in range(true_counts.shape[1]):\n",
    "    correlations.append(pearsonr(true_counts[:,i],predicted[:,i])[0])\n",
    "    if isnan(correlations[-1]):\n",
    "        correlations[-1] = 0\n",
    "print(len(correlations))\n",
    "\n",
    "    \n",
    "plt.figure(\"correlation_vs_mean\",figsize=(20,4))\n",
    "plt.title(\"Correlation of Predictions vs Expression Level\")\n",
    "plt.scatter(correlations,np.mean(true_counts,axis=0),s=.3,c=variation(true_counts,axis=0))\n",
    "plt.ylabel(\"Mean Expression\")\n",
    "plt.xlabel(\"Correlation\")\n",
    "plt.colorbar(label=\"Coefficient of Variation\")\n",
    "plt.clim(0,10)\n",
    "plt.savefig(output_directory+\"correlation_vs_mean_vs_cov.png\",dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = []\n",
    "\n",
    "for i in range(true_counts.shape[1]):\n",
    "    correlations.append(pearsonr(true_counts[:,i],predicted[:,i])[0])\n",
    "    if isnan(correlations[-1]):\n",
    "        correlations[-1] = 0\n",
    "    \n",
    "print(len(correlations))\n",
    "\n",
    "plt.figure(\"correlation_vs_cov\")\n",
    "plt.title(\"Correlation of features vs Coefficient of Variation\")\n",
    "plt.xlabel(\"Coefficient of Variation\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.scatter(variation(true_counts,axis=0),correlations,s=.1,c=np.std(true_counts,axis=0))\n",
    "plt.colorbar(label=\"Standard Deviation of Feature\")\n",
    "plt.xlim(0,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_mask = np.random.rand(*test_counts.flatten().shape) < (subsampling/10.0)\n",
    "\n",
    "errors = prediction_features - true_counts\n",
    "\n",
    "plt.figure(\"error_vs_true_expression\")\n",
    "plt.title(\"Error vs True Expression\")\n",
    "plt.scatter(test_counts.flatten()[random_mask],errors.flatten()[random_mask],s=.3,alpha=.3,c=np.tile(np.mean(test_counts,axis=0),(test_counts.shape[0],1)).flatten()[random_mask],cmap='inferno')\n",
    "plt.xlabel(\"True Expression\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.colorbar(label=\"Mean expression of gene\")\n",
    "plt.plot([])\n",
    "plt.savefig(output_directory+\"error_vs_true_expression.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = prediction_features - test_counts\n",
    "\n",
    "mean_cell_error = np.mean(error,axis=1)\n",
    "mean_gene_error = np.mean(error,axis=0)\n",
    "\n",
    "print(mean_gene_error.shape)\n",
    "print(mean_cell_error.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Distribution of Mean Feature Errors\")\n",
    "plt.hist(mean_gene_error,bins=20)\n",
    "plt.xlabel(\"Mean Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Distribution of Mean Cell Errors\")\n",
    "plt.hist(mean_cell_error,bins=20)\n",
    "plt.xlabel(\"Mean Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression_sorted_features = test_counts.T[np.argsort(np.mean(test_counts,axis=0))].T\n",
    "# expression_sorted_prediction = prediction_features.T[np.argsort(np.mean(test_counts,axis=0))].T\n",
    "\n",
    "\n",
    "plt.figure(\"predictability\")\n",
    "plt.title(\"Correlation of Features to Other Features, Sorted By Mean Expression\")\n",
    "plt.imshow(np.corrcoef(expression_sorted_features.T))\n",
    "plt.colorbar(label=\"Correlation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_sorted_features = test_counts.T[np.argsort(np.mean(test_counts,axis=0))].T\n",
    "\n",
    "random_mask = np.random.rand(*expression_sorted_features.flatten().shape) < subsampling\n",
    "\n",
    "\n",
    "plt.figure(\"ranked_feature_expression\",figsize=(20,4))\n",
    "plt.title(\"Observed Expressions For Each Feature Ranked By Mean Expression\")\n",
    "plt.scatter(np.tile(np.arange(expression_sorted_features.shape[1]),(expression_sorted_features.shape[0],1)).flatten()[random_mask],expression_sorted_features.flatten()[random_mask],s=.3,alpha=.1, label=\"Observed Expression\")\n",
    "# plt.scatter(np.mean(true_counts,axis=0),np.median(true_counts,axis=0),c='r',s=.5, label=\"Mean Expression\")\n",
    "plt.xlabel(\"Feature Rank\")\n",
    "plt.ylabel(\"Observed Expression\")\n",
    "plt.ylim((0,10))\n",
    "plt.legend()\n",
    "plt.savefig(output_directory+\"rank_ordered_expresssion.png\")\n",
    "\n",
    "for cluster in forest.sample_clusters:\n",
    "    cluster_samples = cluster.samples\n",
    "    cluster_counts = forest.output[cluster_samples].T[np.argsort(np.mean(forest.output,axis=0))].T\n",
    "    print(cluster_counts.shape)\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.scatter(np.tile(np.arange(cluster_counts.shape[1]),(cluster_counts.shape[0],1)).flatten(),cluster_counts.flatten(),s=.3,alpha=.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerated_features = test_counts.T[feature_sort].T\n",
    "random_mask = np.random.rand(*agglomerated_features.flatten().shape) < subsampling\n",
    "\n",
    "plt.figure(\"ranked_feature_expression\",figsize=(20,4))\n",
    "plt.title(\"Observed Expressions For Each Feature Ranked By Mean Expression\")\n",
    "plt.scatter(np.tile(np.arange(agglomerated_features.shape[1]),(agglomerated_features.shape[0],1)).flatten()[random_mask],agglomerated_features.flatten()[random_mask],s=.3,alpha=.1, label=\"Observed Expression\")\n",
    "plt.xlabel(\"Feature Rank\")\n",
    "plt.ylabel(\"Observed Expression\")\n",
    "plt.ylim((0,10))\n",
    "plt.legend()\n",
    "plt.savefig(output_directory+\"rank_ordered_expresssion.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quick_hetorskedasticity(feature):\n",
    "#     sorted_feature = sorted(feature)\n",
    "#     first = sorted_feature[:int(len(sorted_feature)/2)]\n",
    "#     second = sorted_feature[int(len(sorted_feature)/2):]\n",
    "#     fv = np.var(first)\n",
    "#     sv = np.var(second)\n",
    "#     return fv,sv\n",
    "\n",
    "# expression_sorted_features.shape\n",
    "\n",
    "# # random_mask = np.random.rand(*expression_sorted_features.flatten().shape) < subsampling\n",
    "\n",
    "# heteroskedasticity = [quick_hetorskedasticity(feature)[0]/quick_hetorskedasticity(feature)[1] for feature in expression_sorted_features.T]\n",
    "# var1 = [quick_hetorskedasticity(feature)[0] for feature in expression_sorted_features.T]\n",
    "# var2 = [quick_hetorskedasticity(feature)[1] for feature in expression_sorted_features.T]\n",
    "\n",
    "# print(var1)\n",
    "# print(var2)\n",
    "\n",
    "# # print(len(heteroskedasticity))\n",
    "\n",
    "# # print(heteroskedasticity)\n",
    "\n",
    "# plt.figure(\"heteroskedasticity\",figsize=(20,4))\n",
    "# plt.title(\"Heteroskedasticity\",fontsize=20)\n",
    "# plt.scatter(np.arange(0,len(var1)),var1,s=4,alpha=1,c='r',label=\"First\")\n",
    "# plt.scatter(np.arange(0,len(var2)),var2,s=4,alpha=1,c='b',label=\"Second\")\n",
    "# # plt.scatter(np.mean(true_counts,axis=0),np.median(true_counts,axis=0),c='r',s=.5, label=\"Mean Expression\")\n",
    "# plt.xlabel(\"Feature Rank\",fontsize=15)\n",
    "# plt.ylabel(\"Ratio\\n Var for f greater than median vs less\",fontsize=12)\n",
    "# plt.legend()\n",
    "# plt.savefig(output_directory+\"heterskedasticity.png\")\n",
    "\n",
    "# plt.figure(\"heteroskedasticity2\",figsize=(20,4))\n",
    "# plt.title(\"Heteroskedasticity\",fontsize=20)\n",
    "# plt.scatter(np.arange(0,len(heteroskedasticity)),heteroskedasticity,s=4,alpha=1,c='b')\n",
    "# plt.xlabel(\"Feature Rank\",fontsize=15)\n",
    "# plt.ylabel(\"Ratio\\n Var for f greater than median vs less\",fontsize=12)\n",
    "# plt.savefig(output_directory+\"heterskedasticity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# for j in range(10):\n",
    "#     i = random.randint(1,true_counts.shape[0])\n",
    "#     plt.figure('cell_multiplex' + str(i))\n",
    "#     plt.scatter(np.arange(expression_sorted_features.shape[1]),expression_sorted_features[i],s=.1)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(10):\n",
    "#     i = random.randint(1,expression_sorted_features.shape[1])\n",
    "#     plt.figure(\"feature_dist_multiplex\" + str(i))\n",
    "#     plt.hist(expression_sorted_features[:,i],bins=50,log=True)\n",
    "#     plt.show()\n",
    "\n",
    "# # deciles = np.zeros((20,expression_sorted_features.shape[1]))\n",
    "# # derivatives = np.zeros((19,expression_sorted_features.shape[1]))\n",
    "# # for i,feature in enumerate(expression_sorted_features.T):\n",
    "# #     bins,edges = np.histogram(feature,bins=20,range=(np.min(feature),np.max(feature)))\n",
    "# # #     print(bins)\n",
    "# # #     print(edges)\n",
    "# # #     print(np.array([y-x for x,y in zip(bins,bins[1:])]))\n",
    "# #     deciles[:,i] = bins\n",
    "# #     derivatives[:,i] = np.array([y-x for x,y in zip(bins,bins[1:])])\n",
    "\n",
    "# # plt.figure(figsize=(20,4))\n",
    "# # plt.imshow(deciles,aspect='auto')\n",
    "# # plt.show()\n",
    "\n",
    "# # plt.figure(figsize=(20,4))\n",
    "# # plt.imshow(derivatives,aspect='auto')\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print true_counts[:10,:10]\n",
    "\n",
    "# expression_sorted_features = test_counts.T[np.argsort(np.mean(test_counts,axis=0))].T\n",
    "\n",
    "# expression_sorted_prediction = prediction.T[np.argsort(np.mean(test_counts,axis=0))].T\n",
    "\n",
    "# random_mask = np.random.rand(*expression_sorted_features.flatten().shape) < (subsampling)\n",
    "\n",
    "# plt.figure(\"ranked_feature_predicted\",figsize=(20,4))\n",
    "# plt.title(\"Predicted Values By Mean Expression Ranking\")\n",
    "# plt.scatter(np.tile(np.arange(expression_sorted_features.shape[1]),(expression_sorted_features.shape[0],1)).flatten()[random_mask],expression_sorted_prediction.flatten()[random_mask],s=.05,alpha=.3,label=\"Expression\",c=np.abs(expression_sorted_prediction-expression_sorted_features).flatten()[random_mask],cmap='plasma')\n",
    "# # plt.scatter(np.arange(expression_sorted_features.shape[1]),np.median(expression_sorted_features,axis=0),c='m',s=.5,label=\"Medians\")\n",
    "# # plt.scatter(np.arange(expression_sorted_features.shape[1]),np.mean(expression_sorted_features,axis=0),c='c',s=.5,label=\"Means\")\n",
    "# plt.legend()\n",
    "# plt.colorbar(label=\"Absolute Value of Error\")\n",
    "# plt.clim(0,10)\n",
    "# plt.savefig(output_directory+\"rank_ordered_predicted.png\",dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_mask = np.random.rand(*expression_sorted_features.flatten().shape) < subsampling\n",
    "\n",
    "# plt.figure(\"error_scatter_ranked\", figsize=(20,4))\n",
    "# plt.title(\"Observed Error By Mean Expression Ranking\")\n",
    "# plt.scatter(np.tile(np.arange(expression_sorted_features.shape[1]),(expression_sorted_features.shape[0],1)).flatten()[random_mask],(expression_sorted_features - expression_sorted_prediction).flatten()[random_mask],alpha=.1,s=.1)\n",
    "# plt.xlabel(\"Rank\")\n",
    "# plt.ylabel(\"Predicted Expression\")\n",
    "# plt.savefig(output_directory+\"rank_ordered_error.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations = []\n",
    "\n",
    "# for i in range(test_counts.shape[1]):\n",
    "    \n",
    "#     correlations.append(pearsonr(test_counts[:,i],prediction[:,i])[0])\n",
    "#     if isnan(correlations[-1]):\n",
    "#         correlations[-1] = 0\n",
    "        \n",
    "# print(len(correlations))\n",
    "# print(test_counts.shape)\n",
    "        \n",
    "# plt.figure(\"correlation_vs_mean\",figsize=(20,4))\n",
    "# plt.title(\"Correlation of Predictions per Expression Ranked Feature\")\n",
    "# plt.scatter(np.arange(len(correlations)),np.array(correlations)[np.argsort(np.mean(test_counts,axis=0))],s=.5)\n",
    "# plt.xlabel(\"Feature Mean Expression Rank\")\n",
    "# plt.ylabel(\"Prediction Correlation\")\n",
    "# plt.savefig(output_directory+\"ranked_correlation.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    " \n",
    "# j = 0\n",
    "\n",
    "# while j < 10:\n",
    "#     i = random.randint(1,expression_sorted_features.shape[1])\n",
    "#     if pearsonr(expression_sorted_features[:,i],expression_sorted_prediction[:,i])[0] < .5:\n",
    "#         continue\n",
    "#     plt.figure('feature_pred_multiplex' + str(i))\n",
    "#     plt.gca().axis('equal')\n",
    "#     plt.title(\"Mean Expresion: \" + str(np.mean(expression_sorted_features[:,i])) + \" Corr: \" + str(pearsonr(expression_sorted_features[:,i],expression_sorted_prediction[:,i])[0]))\n",
    "#     plt.scatter(expression_sorted_features[:,i],expression_sorted_prediction[:,i],s=1)\n",
    "#     plt.xlabel(\"True Expression\")\n",
    "#     plt.ylabel(\"Predicted Expression\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations = []\n",
    "\n",
    "# for i in range(expression_sorted_features.shape[1]):\n",
    "    \n",
    "#     correlations.append(pearsonr(expression_sorted_features[:,i],expression_sorted_prediction[:,i])[0])\n",
    "#     if isnan(correlations[-1]):\n",
    "#         correlations[-1] = 0\n",
    "    \n",
    "# print(len(correlations))\n",
    "# print(correlations[:10])\n",
    "# print(np.arange(.05,1,.05))\n",
    "    \n",
    "# plt.figure(\"correlation_histogram\")\n",
    "# plt.title(\"Distribution of Feature Correlations\")\n",
    "# plt.hist(correlations,bins=np.arange(0,1,.05))\n",
    "# plt.savefig(output_directory+\"correlation_distributions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearsonr(true_counts.flatten(),imputed_gradient.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"Median Random Forest Prediction\")\n",
    "# plt.xlabel(\"Truth\")\n",
    "# plt.ylabel(\"Imputed\")\n",
    "# plt.scatter(truth,pred_basic_forest,s=.003)\n",
    "# plt.plot([0,15],[0,15])\n",
    "# plt.savefig('figures/basic_error_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print np.var(predicted,axis=0).shape\n",
    "\n",
    "# plt.figure(\"means\")\n",
    "# plt.title(\"Distribution of Means\")\n",
    "# plt.hist(np.mean(true_counts,axis=0),bins=np.arange(20),alpha=.1,label=\"Data\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"stds\")\n",
    "# plt.title(\"Distribution of Standard Deviations\")\n",
    "# plt.hist(np.std(true_counts,axis=0), bins=np.arange(20),alpha=.1,label=\"Data\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"naive_mae\")\n",
    "# plt.title(\"Distribution of Means of Error\")\n",
    "# plt.hist(np.mean(np.abs(true_counts - predicted), axis=0),bins=np.arange(20),alpha=.1,label=\"Error\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"naive_mse\")\n",
    "# plt.title(\"Distribution of MSE per feature\")\n",
    "# plt.hist(np.mean((true_counts - predicted)**2, axis=0),bins=np.arange(20),alpha=.1,label=\"Error\")\n",
    "# plt.show()\n",
    "\n",
    "# np.random.shuffle(predicted)\n",
    "# plt.figure(\"mae_shuffled\")\n",
    "# plt.title(\"Distribution of Means of Error (Shuffled)\")\n",
    "# plt.hist(np.var(np.abs(true_counts - predicted),axis=0),bins=np.arange(20),alpha=.1,label=\"Shuffled\")\n",
    "# # plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"Gradient Random Forest Prediction\")\n",
    "# plt.xlabel(\"Truth\")\n",
    "# plt.ylabel(\"Imputed\")\n",
    "# plt.scatter(truth,pred_gradient,s=.003)\n",
    "# plt.plot([0,15],[0,15])\n",
    "# plt.savefig('figures/gradient_error_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print np.sum(true_counts,axis=1).shape\n",
    "\n",
    "# plt.figure(\"cell_histograms\")\n",
    "# plt.title(\"Frequency of Total Cell Counts\")\n",
    "# plt.hist(np.sum(true_counts,axis=1))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power = 2\n",
    "\n",
    "# print(np.sum(true_counts,axis=1).shape)\n",
    "\n",
    "# plt.figure(\"cell_histograms\")\n",
    "# plt.title(\"Frequency of Total Cell Counts (Log)\")\n",
    "# plt.hist(np.sum(np.power(true_counts,power),axis=1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"KNN Imputation\")\n",
    "# plt.xlabel(\"Truth\")\n",
    "# plt.ylabel(\"Imputed\")\n",
    "# plt.scatter(truth,pred_knn,s=.003)\n",
    "# plt.plot([0,15],[0,15])\n",
    "# plt.savefig('figures/knn_error_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"Soft Imputation Prediction\")\n",
    "# plt.xlabel(\"Truth\")\n",
    "# plt.ylabel(\"Imputed\")\n",
    "# plt.scatter(truth,pred_soft,s=.003)\n",
    "# plt.plot([0,15],[0,15])\n",
    "# plt.savefig('figures/soft_error_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"Sklearn Random Forest Prediction\")\n",
    "# plt.xlabel(\"Truth\")\n",
    "# plt.ylabel(\"Imputed\")\n",
    "# plt.scatter(truth,pred_builtin,s=.003)\n",
    "# plt.plot([0,15],[0,15])\n",
    "# plt.savefig('figures/sklearn_rf_error_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_iris = np.loadtxt('./testing/iris.trunc')\n",
    "# dropped_iris = np.loadtxt('./testing/iris.drop')\n",
    "# nan_iris = dropped_iris.copy()\n",
    "# nan_iris[nan_iris == 0] = np.nan\n",
    "\n",
    "# forest_prediction = np.loadtxt('./iris_test/run.prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft_iris = fi.SoftImpute().complete(nan_iris)\n",
    "\n",
    "# knn_iris = fi.KNN(k=15).complete(nan_iris)\n",
    "\n",
    "# factorized_iris = fi.MatrixFactorization().complete(nan_iris)\n",
    "\n",
    "# iterative_iris = fi.IterativeSVD(rank=5).complete(nan_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# guess_mask = dropped_iris.flatten() == 0\n",
    "\n",
    "# truth = true_iris.flatten()[guess_mask] \n",
    "\n",
    "# print \"Pearson correlations of Soft, KNN, Factorized, and Forest\"\n",
    "# print pearsonr(soft_iris.flatten()[guess_mask],truth)\n",
    "# print pearsonr(knn_iris.flatten()[guess_mask],truth)\n",
    "# print pearsonr(factorized_iris.flatten()[guess_mask],truth)\n",
    "# print pearsonr(forest_prediction.flatten()[guess_mask],truth)\n",
    "\n",
    "# print \"MSE of Soft, KNN, Factorized, and Forest\"\n",
    "# print np.mean(((soft_iris.flatten()[guess_mask] - truth) ** 2))\n",
    "# print np.mean(((knn_iris.flatten()[guess_mask] - truth) ** 2))\n",
    "# print np.mean(((factorized_iris.flatten()[guess_mask] - truth) ** 2))\n",
    "# print np.mean(((forest_prediction.flatten()[guess_mask] - truth) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(\"soft_iris\")\n",
    "# plt.title(\"Soft Imptuation of the Iris Dataset\")\n",
    "# plt.xlabel(\"Imputed\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.scatter(soft_iris.flatten()[guess_mask],true_iris.flatten()[guess_mask],s=1)\n",
    "# plt.plot([0,8],[0,8])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"figures/soft_iris_scatter.png\")\n",
    "\n",
    "# plt.figure(\"knn_iris\")\n",
    "# plt.title(\"KNN Imptuation of the Iris Dataset\")\n",
    "# plt.xlabel(\"Imputed\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.scatter(knn_iris.flatten()[guess_mask],true_iris.flatten()[guess_mask],s=1)\n",
    "# plt.plot([0,8],[0,8])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"figures/knn_iris_scatter.png\")\n",
    "\n",
    "# plt.figure(\"factorized_iris\")\n",
    "# plt.title(\"Matrix Factorization Imptuation of the Iris Dataset\")\n",
    "# plt.xlabel(\"Imputed\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.scatter(factorized_iris.flatten()[guess_mask],true_iris.flatten()[guess_mask],s=1)\n",
    "# plt.plot([0,8],[0,8])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"figures/factorized_iris_scatter.png\")\n",
    "\n",
    "# plt.figure(\"forest_iris\")\n",
    "# plt.title(\"Median Forest (Non-Gradient) Imptuation of the Iris Dataset\")\n",
    "# plt.xlabel(\"Imputed\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.scatter(forest_prediction.flatten()[guess_mask],true_iris.flatten()[guess_mask],s=1)\n",
    "# plt.plot([0,8],[0,8])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"figures/forest_iris_scatter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_counts = held_out_counts.copy()\n",
    "# nan_counts[nan_counts == 0] = np.nan\n",
    "\n",
    "# soft_blood = fi.SoftImpute().complete(nan_counts)\n",
    "\n",
    "# knn_blood = fi.KNN(k=15).complete(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = mask.astype(dtype=bool)\n",
    "# # mask = np.logical_and(true_counts != 0, mask)\n",
    "\n",
    "# truth = true_counts[mask].flatten()\n",
    "# pred_basic_forest = imputed_basic[mask].flatten()\n",
    "# pred_gradient = imputed_gradient[mask].flatten()\n",
    "\n",
    "# pred_builtin = imputed_builtin[mask].flatten()\n",
    "\n",
    "# pred_knn = knn_blood[mask].flatten()\n",
    "# pred_soft = soft_blood[mask].flatten()\n",
    "\n",
    "# print \"Pearson of random, gradient, builtin, knn, and soft\"\n",
    "\n",
    "# print pearsonr(truth,pred_basic_forest)\n",
    "# print pearsonr(truth,pred_gradient)\n",
    "# print pearsonr(truth,pred_builtin)\n",
    "# print pearsonr(truth,pred_knn)\n",
    "# print pearsonr(truth,pred_soft)\n",
    "\n",
    "# print \"MSE of random, gradient, builtin, knn, and soft\"\n",
    "\n",
    "# print np.mean((pred_basic_forest - truth) ** 2)\n",
    "# print np.mean((pred_gradient - truth) ** 2)\n",
    "# print np.mean((pred_builtin - truth) ** 2)\n",
    "# print np.mean((pred_knn - truth) ** 2)\n",
    "# print np.mean((pred_soft - truth) ** 2)\n",
    "\n",
    "# print \"Mean absolute error\"\n",
    "# print np.mean(np.abs(pred_basic_forest - truth))\n",
    "# print np.mean(np.abs(pred_gradient - truth))\n",
    "# print np.mean(np.abs(pred_builtin - truth))\n",
    "# print np.mean(np.abs(pred_knn - truth))\n",
    "# print np.mean(np.abs(pred_soft - truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# import time\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# for i in range(10):\n",
    "\n",
    "#     print \"Selecting features\"\n",
    "    \n",
    "#     in_features = np.random.rand(true_counts.shape[1]) > .7\n",
    "#     out_features = np.logical_not(in_features)\n",
    "\n",
    "#     training_samples = np.random.rand(true_counts.shape[0]) > .3\n",
    "#     testing_samples = np.logical_not(training_samples)\n",
    "\n",
    "#     training_in = true_counts[training_samples].T[in_features].T\n",
    "#     training_out = true_counts[training_samples].T[out_features].T\n",
    "\n",
    "#     testing_in = true_counts[testing_samples].T[in_features].T\n",
    "#     testing_out = true_counts[testing_samples].T[out_features].T\n",
    "\n",
    "#     print \"Initializing feature\"\n",
    "    \n",
    "#     forest = GradientBoostingRegressor()\n",
    "\n",
    "#     print \"Fitting\"\n",
    "    \n",
    "#     forest.fit(training_in,training_out)\n",
    "    \n",
    "#     print \"Predicting\"\n",
    "    \n",
    "#     prediction = forest.predict(testing_in)\n",
    "\n",
    "#     print np.sum(in_features)\n",
    "#     print np.sum(out_features)\n",
    "#     print np.sum(training_samples)\n",
    "#     print np.sum(testing_samples)\n",
    "    \n",
    "#     print prediction.shape\n",
    "#     print testing_out.shape\n",
    "    \n",
    "#     print \"Pearson R\"\n",
    "#     print pearsonr(testing_out.flatten(),prediction.flatten())\n",
    "    \n",
    "#     print \"MSE\"\n",
    "#     print np.mean((prediction.flatten() - testing_out.flatten()) ** 2)\n",
    "    \n",
    "#     print \"MAE\"\n",
    "#     print np.mean(np.abs(prediction.flatten() - testing_out.flatten()))\n",
    "\n",
    "    \n",
    "# print \"Fitting done\"\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# print start_time - end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# import time\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# for i in range(10):\n",
    "\n",
    "#     print \"Selecting features\"\n",
    "    \n",
    "#     in_features = np.random.rand(true_counts.shape[1]) > .7\n",
    "#     out_features = np.logical_not(in_features)\n",
    "\n",
    "#     training_samples = np.random.rand(true_counts.shape[0]) > .3\n",
    "#     testing_samples = np.logical_not(training_samples)\n",
    "\n",
    "#     training_in = true_counts[training_samples].T[in_features].T\n",
    "#     training_out = true_counts[training_samples].T[out_features].T\n",
    "\n",
    "#     testing_in = true_counts[testing_samples].T[in_features].T\n",
    "#     testing_out = true_counts[testing_samples].T[out_features].T\n",
    "\n",
    "#     print \"Initializing feature\"\n",
    "    \n",
    "#     forest = RandomForestRegressor(n_estimators=100,min_samples_split=50,n_jobs=int(10),max_features=400)\n",
    "\n",
    "#     print \"Fitting\"\n",
    "    \n",
    "#     forest.fit(training_in,training_out)\n",
    "    \n",
    "#     print \"Predicting\"\n",
    "    \n",
    "#     prediction = forest.predict(testing_in)\n",
    "\n",
    "#     print np.sum(in_features)\n",
    "#     print np.sum(out_features)\n",
    "#     print np.sum(training_samples)\n",
    "#     print np.sum(testing_samples)\n",
    "    \n",
    "#     print prediction.shape\n",
    "#     print testing_out.shape\n",
    "    \n",
    "#     print \"Pearson R\"\n",
    "#     print pearsonr(testing_out.flatten(),prediction.flatten())\n",
    "    \n",
    "#     print \"MSE\"\n",
    "#     print np.mean((prediction.flatten() - testing_out.flatten()) ** 2)\n",
    "    \n",
    "#     print \"MAE\"\n",
    "#     print np.mean(np.abs(prediction.flatten() - testing_out.flatten()))\n",
    "\n",
    "    \n",
    "# print \"Fitting done\"http://localhost:8888/notebooks/evaluate_prediction.ipynb#\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# print start_time - end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# braid = trbr.IHMM.reconstitute('./forest_vision_braid')\n",
    "# braid = trbr.IHMM(forest,beta=100,gamma=100,start_states=100,alpha_e=.5,beta_e=.5,inf_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(300):\n",
    "#     print(\"********\")\n",
    "#     print(i)\n",
    "#     print(braid.alpha)\n",
    "#     print(braid.beta)\n",
    "#     print(braid.gamma)\n",
    "#     print(len(braid.hidden_states))\n",
    "#     print(\"********\")\n",
    "#     braid.sample_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     print(\"********\")\n",
    "#     print(f\"SWEEP:{i}\")\n",
    "#     print(f\"Beta:{braid.beta}\")\n",
    "#     print(f\"Gamma:{braid.gamma}\")\n",
    "#     braid.sweep()\n",
    "#     braid.max_likelihood_sweep()\n",
    "#     if i%3 == 0:\n",
    "#         braid.max_likelihood_sweep()\n",
    "#     print(braid.oracle_transition_counts)\n",
    "#     print(braid.transition_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(np.sum(braid.state_masks,axis=1))\n",
    "# print(braid.state_sample_log_odds.shape)\n",
    "# # print(list(braid.state_sample_log_odds[1]))\n",
    "# # print(list(braid.state_raw_emission_counts[1]))\n",
    "# # print(list(enumerate(np.sum(braid.state_masks,axis=1))))\n",
    "# print(np.arange(12550)[braid.state_masks[9]])\n",
    "# ni = 8720\n",
    "# print(braid.state_log_odds_given_divergence[:,ni])\n",
    "# print(braid.state_log_odds_given_child_l[:,ni])\n",
    "# print(braid.state_log_odds_given_child_r[:,ni])\n",
    "# print(braid.state_log_odds[:,ni])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sorted(enumerate(np.mean(braid.state_log_odds_given_divergence[:,braid.live_mask],axis=0)),key=lambda x: x[1]))\n",
    "\n",
    "# ni = 98\n",
    "# print(braid.state_log_odds_given_divergence[:,ni])\n",
    "# print(braid.state_log_odds_given_child_l[:,ni])\n",
    "# print(braid.state_log_odds_given_child_r[:,ni])\n",
    "# print(braid.state_log_odds[:,ni])\n",
    "\n",
    "# print(braid.state_log_odds[:,ni])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# braid.node_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     braid.sweep()\n",
    "#     if i%5 == 0:\n",
    "#         braid.max_likelihood_sweep()\n",
    "# list(braid.state_sample_log_odds[1])\n",
    "# np.sum(np.abs(braid.state_sample_log_odds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iftc = forest.tsne_encoding()\n",
    "# iftc = forest.tsne(override=True)\n",
    "\n",
    "# cell_id_header = np.loadtxt('/Users/boris/taylor/vision/python_prototype/raw_data/vision_sc/cell_id_header.txt',dtype='str')\n",
    "# cell_ids = np.loadtxt('/Users/boris/taylor/vision/python_prototype/raw_data/vision_sc/cell_identity.txt',dtype=bool)\n",
    "\n",
    "# mep_index = list(cell_id_header).index('MEP_narrow')\n",
    "\n",
    "# print(mep_index)\n",
    "# print(np.sum(cell_ids[:,mep_index]))\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(iftc[:,0],iftc[:,1],c=cell_ids[:,mep_index])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"State Transition Frequency,0 is Root\")\n",
    "# plt.imshow(forest.split_cluster_transition_matrix(depth=4),cmap='binary')\n",
    "# plt.show()\n",
    "  \n",
    "# # print(braid.state_raw_sample_odds[1])\n",
    "# for hidden_state in range(braid.hidden_states):\n",
    "#     print(np.sum(braid.state_masks[hidden_state]))\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.title(f\"Hidden State {hidden_state}\",fontsize=20)\n",
    "#     plt.scatter(iftc[:,0],iftc[:,1],c=braid.lr_finite(hidden_state),cmap='bwr',s=.3)\n",
    "#     plt.ylim(-30,30)\n",
    "#     plt.xlim(-30,40)\n",
    "# #     plt.colorbar()\n",
    "# #     plt.scatter(iftc[:,0],iftc[:,1],c=braid.state_raw_sample_odds[hidden_state],s=1,cmap='PuOr')\n",
    "#     plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"Frequency of Transitions from One Hidden State To Another\")\n",
    "# plt.imshow(braid.pad_root_transitions(braid.raw_transition_counts()).T,cmap='binary')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.plot_sample_feature_split(braid.lr_finite(14),plot_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# braid.backup('./forest_vision_braid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(7))[:20])\n",
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(8))[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(3))[:20])\n",
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(4))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(13))[:20])\n",
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(14))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(11))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(5))[:20])\n",
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(6))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(1))[:20])\n",
    "# print(forest.node_feature_summary(braid.hidden_state_to_nodes(2))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in forest.node_feature_summary(braid.hidden_state_to_nodes(9)):\n",
    "#     print(f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from goatools.base import download_go_basic_obo\n",
    "# obo_fname = download_go_basic_obo()\n",
    "\n",
    "# from goatools.base import download_ncbi_associations\n",
    "# gene2go = download_ncbi_associations()\n",
    "\n",
    "\n",
    "# from goatools.obo_parser import GODag\n",
    "\n",
    "# obodag = GODag(\"go-basic.obo\")\n",
    "\n",
    "# from goatools.associations import read_ncbi_gene2go,dnld_assc\n",
    "\n",
    "# geneid2gos_mouse = read_ncbi_gene2go(\"gene2go\", taxids=[10090])\n",
    "\n",
    "# print(\"{N:,} annotated mouse genes\".format(N=len(geneid2gos_mouse)))\n",
    "\n",
    "# from goatools.go_enrichment import GOEnrichmentStudy\n",
    "# from goatools.test_data.genes_NCBI_10090_ProteinCoding import GENEID2NT as GeneID2nt_mus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goeaobj = GOEnrichmentStudy(\n",
    "#         GeneID2nt_mus.keys(), # List of mouse protein-coding genes\n",
    "#         geneid2gos_mouse, # geneid/GO associations\n",
    "#         obodag, # Ontologies\n",
    "#         propagate_counts = False,\n",
    "#         alpha = 0.05, # default significance cut-off\n",
    "#         methods = ['fdr_bh']) # defult multipletest correction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbol2id = {v[5]:k for k,v in GeneID2nt_mus.items()}\n",
    "\n",
    "# def try_symbol(symbols):\n",
    "#     ids = []\n",
    "#     for symbol in symbols:\n",
    "#         if symbol in symbol2id:\n",
    "#             ids.append(symbol2id[symbol])\n",
    "#     return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gores = goeaobj.run_study(try_symbol([x[0] for x in forest.node_feature_summary(braid.hidden_state_to_nodes(13))]))\n",
    "\n",
    "# gores_filtered = sorted([r for r in gores if r.p_fdr_bh < 0.05],key=lambda r: r.p_fdr_bh)\n",
    "\n",
    "# gores_filtered = [g for g in gores_filtered if g.goterm.namespace == 'biological_process' or g.goterm.namespace == 'molecular_function']\n",
    "\n",
    "# print(gores_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gores_filtered[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [go.name for go in gores_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for term in [go.name for go in gores_filtered]:\n",
    "#     print(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.cm import get_cmap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "rainbow=get_cmap('rainbow')\n",
    "\n",
    "cluster_names = [\"None\",] + list(cell_identity_header[9:-1])\n",
    "cluster_names = np.array([cluster_names]).T\n",
    "clusters = sorted(list(set(cell_identity)))\n",
    "clusters = np.array([clusters]).T\n",
    "colors = np.array([rainbow(c/len(clusters)) for c in clusters]).T.T\n",
    "\n",
    "print(cluster_names)\n",
    "print(clusters)\n",
    "print(colors)\n",
    "\n",
    "# coordinates = forest.coordinates(type='tsne',pca=True,override=False)\n",
    "coordinates = TSNE().fit_transform(PCA(n_components=2).fit_transform(counts))\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "scatter_ax = fig.add_axes([0,0,1,1])\n",
    "scatter_ax.set_title(\"Mouse Hematopoietic Cells By Type, FACS\",color='w')\n",
    "scatter_ax.scatter(coordinates[:,0],coordinates[:,1],c=cell_identity,cmap='rainbow',s=20)\n",
    "scatter_ax.set_xticks([])\n",
    "scatter_ax.set_yticks([])\n",
    "table_ax = fig.add_axes([.05,.05,.1,.3])\n",
    "table_ax.axis(\"off\")\n",
    "table_ax.table(cellText=cluster_names,cellColours=colors,bbox=[0,0,1,1],)\n",
    "plt.show()\n",
    "\n",
    "colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(cell_x_split.shape[0]):\n",
    "    for j in range(cell_x_split.shape[1]):\n",
    "        print((i,j))\n",
    "        cell_id_mask = np.array(cell_identity) == j\n",
    "        print(np.sum(cell_id_mask))\n",
    "        cluster_cell_scores = np.array(forest.split_clusters[i].cell_scores())\n",
    "#         print(cluster_cell_scores)\n",
    "#         print(cell_id_mask)\n",
    "#         print(np.array(cluster_cell_scores)[np.array(cell_id_mask)])\n",
    "        mean_cluster_score = np.mean(np.array(cluster_cell_scores)[np.array(cell_id_mask)])\n",
    "#         print(mean_cluster_score)\n",
    "        cell_x_split[i,j] = mean_cluster_score\n",
    "        \n",
    "cluster_sort = dendrogram(linkage(cell_x_split,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "# cluster_sort = np.argsort(np.array([c.mean_level() for c in forest.split_clusters]))\n",
    "cell_id_sort = dendrogram(linkage(cell_x_split.T,metric='cos',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cell_x_split[cluster_sort].T[cell_id_sort],aspect='auto',cmap='binary')\n",
    "plt.xticks(np.arange(19),cluster_sort)\n",
    "plt.yticks(np.arange(12), np.array([\"None\",] + list(cell_identity_header[9:-1]))[cell_id_sort])\n",
    "plt.xlabel(\"RF Clusters\")\n",
    "plt.ylabel(\"FACS Profile\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
