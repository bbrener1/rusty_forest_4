{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook will go through a conventional scanpy analysis of citeseq data, so that we can compare it to an \n",
    "# analysis performed by a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we load the data, fortunately the facilities for this are pretty nice\n",
    "\n",
    "datasets = [\n",
    "    '/localscratch/bbrener1/johnston_sc/Retina2/outs/filtered_gene_bc_matrices/dmel_r6.20/matrix.mtx',\n",
    "    '/home/bbrener1/transfer/all_raw/raw_data/nelmari/ctrl/matrix.mtx',\n",
    "    '/home/bbrener1/transfer/all_raw/raw_data/fan_tendon/TH1/matrix.mtx',\n",
    "    '/home/bbrener1/transfer/all_raw/raw_data/citeseq/GSE100866_CBMC_human_umis.tsv', # This dataset had spiked in mouse cells\n",
    "                                                                                      # but this is a filtered matrix\n",
    "        \n",
    "    '/home/bbrener1/transfer/all_raw/raw_data/vision_sc/raw_counts.txt',   # These are the unfiltered UMIs of this dataset\n",
    "                                                                           # Actual paper analysis was done on like 1600 cells, so needs to be checked out\n",
    "]\n",
    "# Whether this dataset needs to be transposed\n",
    "transpose = [\n",
    "    True,\n",
    "    True,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "]\n",
    "\n",
    "scanpy_objects = []\n",
    "umi_objects = []\n",
    "\n",
    "for dataset,d_transpose in zip(datasets,transpose): \n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "    large_scanpy_object = sc.read(dataset)\n",
    "    \n",
    "    if d_transpose:\n",
    "        large_scanpy_object = large_scanpy_object.T\n",
    "\n",
    "    sc.pp.downsample_counts(large_scanpy_object,counts_per_cell=1200)\n",
    "    large_scanpy_object.X = large_scanpy_object.X.astype(dtype=float)\n",
    "        \n",
    "    sc.pp.filter_cells(large_scanpy_object,min_genes=100)\n",
    "    sc.pp.filter_cells(large_scanpy_object,min_counts=100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Read in\")\n",
    "#     This filtration is roughly analogous to the standard zheng, but it retains the UMI object. \n",
    "\n",
    "    sc.pp.filter_genes(large_scanpy_object, min_counts=10)         # only consider genes with more than 10 counts\n",
    "\n",
    "    \n",
    "    scpy_copy = large_scanpy_object.copy()\n",
    "    sc.pp.normalize_per_cell(scpy_copy)\n",
    "    filter_result = sc.pp.filter_genes_dispersion(  # select highly-variable genes\n",
    "        scpy_copy.X, flavor='cell_ranger', n_top_genes=2000, log=False\n",
    "    )\n",
    "    scpy_filtered = large_scanpy_object[:, filter_result.gene_subset].copy()     # subset the genes\n",
    "    \n",
    "    del(large_scanpy_object)\n",
    "        \n",
    "    umis = scpy_filtered.copy().X\n",
    "\n",
    "    sc.pp.normalize_per_cell(scpy_filtered)                 # renormalize after filtering\n",
    "    sc.pp.log1p(scpy_filtered)                      # log transform: adata.X = log(adata.X + 1)\n",
    "    sc.pp.scale(scpy_filtered)\n",
    "\n",
    "#     print(f\"zero mean:{np.sum(np.mean(umis,axis=0) == 0)}/{np.mean(umis,axis=0).shape}\")\n",
    "#     print(f\"zero var:{np.sum(np.var(umis,axis=0) == 0)}\")\n",
    "    \n",
    "    scanpy_objects.append(scpy_filtered)\n",
    "    umi_objects.append(umis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,umi in enumerate(umi_objects):\n",
    "    print(type(umi))\n",
    "    if type(umi) is not type(np.zeros(0)):\n",
    "        umi_objects[i] = np.array(umi.todense())\n",
    "    print(umi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,umi in enumerate(umi_objects):\n",
    "    print(type(umi))\n",
    "    print(umi.shape)\n",
    "    print(f\"zero mean:{np.sum(np.mean(umi,axis=0) == 0)}/{np.mean(umis,axis=0).shape}\")\n",
    "    print(f\"zero var:{np.sum(np.var(umi,axis=0) == 0)}\")\n",
    "    print(np.log(np.mean(umi,axis=0)))\n",
    "    print(np.log(np.var(umi,axis=0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we set down the parameter space to be explored. \n",
    "#\n",
    "# We will set up certain defualt values, and then perform testing on how deviation from these values affects \n",
    "# the results of clustering by two agnostic measures: Silhouette and Calinski-Harabasz scores, per SK-Learn\n",
    "\n",
    "defaults = {\n",
    "    'trees':100,\n",
    "    'braids':3,\n",
    "    'ifs':500,\n",
    "    'ofs':500,\n",
    "    'ss':200,\n",
    "    'depth':8,\n",
    "    'leaves':50,\n",
    "    'sfr':0.,\n",
    "    'forest_metric':'ssme',\n",
    "    'regularization':'l1',\n",
    "    'clustering_strategy':'encoding',\n",
    "    'k':10,\n",
    "    'sub':.5,\n",
    "    'clustering_metric':'cos'\n",
    "}\n",
    "\n",
    "\n",
    "alternatives = {\n",
    "    'trees':[30,100,300],\n",
    "    'braids':[1,3,5],\n",
    "    'ifs':[100,500,1000],\n",
    "    'ofs':[100,500,1000],\n",
    "    'ss':[50,200,1000],\n",
    "#     'depth':[4,8,10],\n",
    "    'leaves':[20,50,100,400],\n",
    "    'sfr':[0,0.5,1.],\n",
    "#     'forest_metric':['ssme','var'],\n",
    "    'clustering_strategy':['encoding','leaf'],\n",
    "#     'clustering_algorithm':['sdg','louvain'],\n",
    "    'k':[10,20,30],\n",
    "    'sub':[.3,.5,.8],\n",
    "    'clustering_metric':['cos','jaccard']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/localscratch/bbrener1/rusty_forest_v3/src')\n",
    "# sys.path.append('../src')\n",
    "import tree_reader as tr \n",
    "import lumberjack\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import calinski_harabasz_score,silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "umis = umi_objects[0]\n",
    "\n",
    "tsne = TSNE().fit_transform(PCA(n_components=100).fit_transform(umis))\n",
    "\n",
    "johnston_forests = {p:[] for p in alternatives.keys()}\n",
    "johnston_calinski_harabasz = {p:[] for p in alternatives.keys()}\n",
    "johnston_silhouette = {p:[] for p in alternatives.keys()}\n",
    "\n",
    "for parameter in alternatives.keys():\n",
    "    print(f\"Iterating over {parameter}\")\n",
    "    for alternative in alternatives[parameter]:\n",
    "        print(f\"Trying {alternative}\")\n",
    "        \n",
    "        parameters = deepcopy(defaults)\n",
    "        parameters[parameter] = alternative\n",
    "        \n",
    "        print(parameters)\n",
    "\n",
    "        forest = lumberjack.fit(\n",
    "            umis,\n",
    "            trees=parameters['trees'],\n",
    "            braids=parameters['braids'],\n",
    "            ifs=parameters['ifs'],\n",
    "            ofs=parameters['ofs'],\n",
    "            ss=parameters['ss'],\n",
    "            depth=parameters['depth'],\n",
    "            leaves=parameters['leaves'],\n",
    "            sfr=parameters['sfr']\n",
    "        )\n",
    "        \n",
    "        if parameters['clustering_strategy'] == 'encoding':\n",
    "            if parameters['clustering_metric'] == 'cos':\n",
    "                forest.cluster_samples_encoding(\n",
    "                    pca=100,\n",
    "                    k=parameters['k'],\n",
    "                    sub=parameters['sub'],\n",
    "                    metric=parameters['clustering_metric'],\n",
    "                )\n",
    "            elif parameters['clustering_metric'] == 'jaccard':\n",
    "                forest.cluster_samples_encoding(\n",
    "                    k=parameters['k'],\n",
    "                    sub=parameters['sub'],\n",
    "                    metric=parameters['clustering_metric'],\n",
    "                )\n",
    "            else:\n",
    "                raise Exception\n",
    "        elif parameters['clustering_strategy'] == 'leaf':\n",
    "            forest.cluster_leaves_samples(\n",
    "                k=parameters['k'],\n",
    "                sub=parameters['sub'],\n",
    "                metric=parameters['clustering_metric'],\n",
    "            )\n",
    "            forest.cluster_samples_leaf_cluster()\n",
    "        else:\n",
    "            raise Exception\n",
    "        \n",
    "        forest.tsne_coordinates = tsne\n",
    "        forest.plot_sample_clusters()\n",
    "        \n",
    "    \n",
    "        johnston_forests[parameter].append(forest)\n",
    "        johnston_calinski_harabasz[parameter].append(calinski_harabasz_score(umis,forest.sample_labels))\n",
    "        johnston_silhouette[parameter].append(silhouette_score(umis,forest.sample_labels))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "umis = umi_objects[3]\n",
    "\n",
    "tsne = TSNE().fit_transform(PCA(n_components=100).fit_transform(umis))\n",
    "\n",
    "citeseq_forest = {p:[] for p in alternatives.keys()}\n",
    "citeseq_calinski_harabasz = {p:[] for p in alternatives.keys()}\n",
    "citeseq_silhouette = {p:[] for p in alternatives.keys()}\n",
    "\n",
    "for parameter in alternatives.keys():\n",
    "    print(f\"Iterating over {parameter}\")\n",
    "    for alternative in alternatives[parameter]:\n",
    "        print(f\"Trying {alternative}\")\n",
    "        \n",
    "        parameters = deepcopy(defaults)\n",
    "        parameters[parameter] = alternative\n",
    "        \n",
    "        print(parameters)\n",
    "\n",
    "        forest = lumberjack.fit(\n",
    "            umis,\n",
    "            trees=parameters['trees'],\n",
    "            braids=parameters['braids'],\n",
    "            ifs=parameters['ifs'],\n",
    "            ofs=parameters['ofs'],\n",
    "            ss=parameters['ss'],\n",
    "            depth=parameters['depth'],\n",
    "            leaves=parameters['leaves'],\n",
    "            sfr=parameters['sfr']\n",
    "        )\n",
    "        \n",
    "        if parameters['clustering_strategy'] == 'encoding':\n",
    "            if parameters['clustering_metric'] == 'cos':\n",
    "                forest.cluster_samples_encoding(\n",
    "                    pca=100,\n",
    "                    k=parameters['k'],\n",
    "                    sub=parameters['sub'],\n",
    "                    metric=parameters['clustering_metric'],\n",
    "                )\n",
    "            elif parameters['clustering_metric'] == 'jaccard':\n",
    "                forest.cluster_samples_encoding(\n",
    "                    k=parameters['k'],\n",
    "                    sub=parameters['sub'],\n",
    "                    metric=parameters['clustering_metric'],\n",
    "                )\n",
    "            else:\n",
    "                raise Exception\n",
    "        elif parameters['clustering_strategy'] == 'leaf':\n",
    "            forest.cluster_leaves_samples(\n",
    "                k=parameters['k'],\n",
    "                sub=parameters['sub'],\n",
    "                metric=parameters['clustering_metric'],\n",
    "            )\n",
    "            forest.cluster_samples_leaf_cluster()\n",
    "        else:\n",
    "            raise Exception\n",
    "        \n",
    "        forest.tsne_coordinates = tsne\n",
    "        forest.plot_sample_clusters()\n",
    "        \n",
    "    \n",
    "        citeseq_forests[parameter].append(forest)\n",
    "        citeseq_calinski_harabasz[parameter].append(calinski_harabasz_score(umis,forest.sample_labels))\n",
    "        citeseq_silhouette[parameter].append(silhouette_score(umis,forest.sample_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session(\"scanpy_calinski_silhouette.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in alternatives.keys():\n",
    "    \n",
    "    jh_ch_results = johnston_calinski_harabasz[parameter]\n",
    "    jh_ar = np.arange(len(ch_results))\n",
    "    plt.figure()\n",
    "    plt.title(f\"Calinski-Harabasz:{parameter}\")\n",
    "    plt.bar(jh_ar,jh_ch_results,tick_labels=alternatives[parameter])\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir forest_alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in alternatives.keys():\n",
    "    for i,forest in enumerate(johnston_forests[parameter]):\n",
    "        forest.backup('./forest_alternatives/' + parameter + str(i) + \".forest\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_forest = johnston_forests['trees'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
