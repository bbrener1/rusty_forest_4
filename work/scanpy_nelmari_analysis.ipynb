{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook will go through a conventional scanpy analysis of citeseq data, so that we can compare it to an \n",
    "# analysis performed by a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we load the data, fortunately the facilities for this are pretty nice\n",
    "\n",
    "nelmari = sc.read('/home/bbrener1/transfer/all_raw/raw_data/nelmari/ctrl/matrix.mtx')\n",
    "nelmari.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data is transposed from how it would appear in R ðŸ™„\n",
    "\n",
    "nelmari = nelmari.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This isn't mixed species data, and the cells have already undergone preliminary filtration by cellranger, \n",
    "# so filter primarily by features:\n",
    "\n",
    "sc.pp.filter_genes(nelmari, min_counts=1)         # only consider genes with more than 1 count\n",
    "nelmari_copy = nelmari.copy()\n",
    "sc.pp.normalize_per_cell(nelmari_copy)\n",
    "filter_result = sc.pp.filter_genes_dispersion(  # select highly-variable genes\n",
    "    nelmari_copy.X, flavor='cell_ranger', n_top_genes=2000, log=False\n",
    ")\n",
    "nelmari_filtered = nelmari[:, filter_result.gene_subset]     # subset the genes\n",
    "\n",
    "umis = nelmari.copy().X.todense()\n",
    "\n",
    "sc.pp.normalize_per_cell(nelmari_filtered)                 # renormalize after filtering\n",
    "sc.pp.log1p(nelmari_filtered)                      # log transform: adata.X = log(adata.X + 1)\n",
    "sc.pp.scale(nelmari_filtered)\n",
    "\n",
    "nelmari_working = nelmari_filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(umis.shape)\n",
    "print(umis[20:30,20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/localscratch/bbrener1/rusty_forest_v3/src')\n",
    "# sys.path.append('../src')\n",
    "import tree_reader as tr \n",
    "import lumberjack\n",
    "\n",
    "# forest = lumberjack.fit(\n",
    "#     np.array(johnston_working.X),\n",
    "#     trees=100,\n",
    "#     braids=3,\n",
    "#     ifs=500,\n",
    "#     ofs=500,\n",
    "#     ss=200,\n",
    "#     depth=8,\n",
    "#     leaves=100,\n",
    "#     sfr=0\n",
    "# )\n",
    "\n",
    "\n",
    "forest = lumberjack.fit(\n",
    "    umis,\n",
    "    trees=100,\n",
    "    braids=3,\n",
    "    ifs=500,\n",
    "    ofs=500,\n",
    "    ss=200,\n",
    "    depth=8,\n",
    "    leaves=50,\n",
    "    sfr=0\n",
    ")\n",
    "\n",
    "forest.set_cache(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.backup(\"scanpy_cmp_nelmari\")\n",
    "# forest = tr.Forest.reconstitute('scanpy_cmp_johnston')\n",
    "# forest.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.reset_sample_clusters()\n",
    "forest.cluster_samples_encoding(sub=.8,k=10,depth=8,metric='jaccard')\n",
    "# forest.cluster_samples_encoding(sub=.5,k=10,depth=8,metric='cosine',pca=100)\n",
    "\n",
    "# forest.reset_leaf_clusters()\n",
    "# forest.cluster_leaves_samples(sub=.5,k=20,depth=6,metric=\"jaccard\")\n",
    "# forest.cluster_leaves_samples(sub=.8,k=20,metric=\"cosine\",pca=100)\n",
    "# forest.cluster_leaves_predictions(sub=.8,k=20,metric=\"cosine\",pca=100,mode=\"mean\")\n",
    "# forest.cluster_samples_leaf_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest.tsne(pca=100)\n",
    "forest.plot_sample_clusters()\n",
    "# forest.trees[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cluster in forest.leaf_clusters:\n",
    "    cluster.plot_sample_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.reset_split_clusters()\n",
    "forest.interpret_splits(sub=.8,relatives=True,pca=30,depth=5,mode='additive_mean',metric='cosine',k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# forest.tsne_coordinates = \n",
    "# forest.tsne(pca=100)\n",
    "forest.most_likely_tree(depth=5)\n",
    "# forest.maximum_spanning_tree(depth=5)\n",
    "forest.html_tree_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now establish the neighbor graph because several methods rely on it\n",
    "\n",
    "sc.pp.neighbors(nelmari_working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(nelmari_working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(nelmari_working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to do clusterin via Louvain as one of the gold standards\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sc.tl.louvain(nelmari_working,resolution=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(nelmari_working,color='louvain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.tsne(nelmari_working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.tsne(nelmari_working,color='louvain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.scatter(*citeseq_scaled.obsm['X_tsne'].T,c=forest.sample_labels,s=4,cmap='rainbow')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(*nelmari_working.obsm['X_umap'].T,c=forest.sample_labels,s=4,cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.tsne_coordinates = johnston_working.obsm['X_umap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest.plot_sample_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.reset_split_clusters()\n",
    "forest.interpret_splits(mode='additive_mean',depth=5,sub=.5,k=20,metric='cosine',relatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_cluster in forest.split_clusters:\n",
    "    split_cluster.html_sister_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.maximum_spanning_tree(depth=5)\n",
    "# forest.most_likely_tree(depth=5)\n",
    "forest.html_tree_summary(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(forest.nodes(root=True,depth=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we wish to examine the behavior of distributions within clusters as defined by louvain and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umi_means = np.array(np.mean(umis,axis=0)).ravel()\n",
    "umi_vars = np.array(np.var(umis,axis=0)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umi_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"UMI Mean vs Variance per feature, Log/Log\")\n",
    "plt.scatter(np.log(umi_means),np.log(umi_vars),s=1)\n",
    "plt.plot([-8,4],[-8,4],c='red')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"UMI Mean vs Variance per feature, Linear\")\n",
    "plt.scatter(umi_means,umi_vars,s=1)\n",
    "plt.plot([0,10],[0,10],c='red')\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,10)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"UMI Mean vs Variance per feature, Linear, low range\")\n",
    "plt.scatter(umi_means,umi_vars,s=1)\n",
    "plt.plot([0,1],[0,1],c='red')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"UMI Mean/Variance Ratio per feature, Linear\")\n",
    "plt.scatter(np.arange(umi_means.shape[0]),(umi_means/umi_vars)[np.argsort(umi_means)],s=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cluster in set(johnston_working.obs['louvain']):\n",
    "    mask = johnston_working.obs['louvain'] == cluster\n",
    "    filtered_cells = np.array(umis[mask])\n",
    "    cluster_means = np.mean(filtered_cells,axis=0)\n",
    "    cluster_var = np.var(filtered_cells,axis=0)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(np.log(cluster_means),np.log(cluster_var),s=1)\n",
    "    plt.plot([-8,4],[-8,4],c='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we wish to examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cluster in set(forest.sample_labels):\n",
    "    mask = forest.sample_labels == cluster\n",
    "    filtered_cells = np.array(umis[mask])\n",
    "    cluster_means = np.mean(filtered_cells,axis=0)\n",
    "    cluster_var = np.var(filtered_cells,axis=0)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title(f\"Cluster:{cluster}\")\n",
    "    plt.scatter(np.log(cluster_means),np.log(cluster_var),s=1)\n",
    "    plt.plot([-8,4],[-8,4],c='red')\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title(f\"UMI Mean/Variance Ratio per feature, Cluster:{cluster}\")\n",
    "    plt.scatter(np.arange(cluster_means.shape[0]),(cluster_means/cluster_var)[np.argsort(cluster_means)],s=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.argsort(np.mean(umis.X,axis=0))[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest,poisson,nbinom\n",
    "\n",
    "def poisson_ks_check(x):\n",
    "    mean = np.mean(x)\n",
    "    cdf = lambda x: poisson.cdf(x,mean)\n",
    "    return kstest(x,cdf)\n",
    "\n",
    "# Correctly fitting a negative binomial is a pain, here is a hacked out version for now:\n",
    "def nb_pr_estimation(x):\n",
    "    mean = np.mean(x)\n",
    "    var = np.var(x)\n",
    "    counter = mean/var\n",
    "        \n",
    "    p = -1 * (counter - 1)\n",
    "    r = mean * ((1-p)/p)\n",
    "        \n",
    "    return p,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_draws = nbinom.rvs(4,.5,size=1000)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(nb_draws)\n",
    "plt.show()\n",
    "\n",
    "nb_pr_estimation(nb_draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks_values = [poisson_ks_check(x)[0] for x in forest.output.T]\n",
    "print(ks_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Kolomogorov-Smirnov Test Statistic Vs ML Estimated Poisson Distribution vs Mean, Global\")\n",
    "plt.scatter(umi_means,ks_values[:2000],s=1)\n",
    "plt.xlabel(\"Mean\")\n",
    "plt.ylabel(\"K-S Statistic\")\n",
    "plt.xlim(0,40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cluster in set(forest.sample_labels):\n",
    "    mask = forest.sample_labels == cluster\n",
    "    filtered_cells = np.array(umis[mask])\n",
    "\n",
    "    ks_values = [poisson_ks_check(x)[0] for x in filtered_cells.T]\n",
    "    means = np.mean(filtered_cells,axis=0)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(f\"Kolomogorov-Smirnov Test Statistic Vs ML Estimated Poisson Distribution vs Mean, Cluster {cluster}\")\n",
    "    plt.scatter(means,ks_values[:2000],s=1)\n",
    "    plt.xlabel(\"Mean\")\n",
    "    plt.ylabel(\"K-S Statistic\")\n",
    "    plt.xlim(0,30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cluster in set(forest.sample_labels):\n",
    "    mask = forest.sample_labels == cluster\n",
    "    filtered_cells = np.array(umis[mask])\n",
    "\n",
    "    size_factors = np.sum(filtered_cells,axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(f\"Size factor distributions, Cluster {cluster}\")\n",
    "    plt.hist(np.array(size_factors),log=True,bins=np.arange(0,50000,200))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_factors = np.array(np.sum(np.array(umis),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(size_factors,bins=np.arange(0,50000,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA.fit_transform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
