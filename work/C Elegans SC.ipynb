{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram,linkage\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "raw_data_location = \"/localscratch/bbrener1/c_elegans_raw_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of single cell RNAseq data for C. elegans. \n",
    "\n",
    "# Source paper: Cao, Junyue, Jonathan S. Packer, Vijay Ramani, Darren A. Cusanovich, Chau Huynh, Riza Daza, Xiaojie Qiu et al. \"Comprehensive single-cell transcriptional profiling of a multicellular organism.\" Science 357, no. 6352 (2017): 661-667.\n",
    "\n",
    "# Url: https://science.sciencemag.org/content/357/6352/661.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first obtain the count matrix in an annoying format:\n",
    "\n",
    "%cd {raw_data_location}\n",
    "\n",
    "!wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2599nnn/GSM2599701/suppl/GSM2599701%5FGene%2Ecount%2Ematrix%2Ecelegans%2Ecell%2ERdata%2Egz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuck you very much Dr. Cao, for making me install fucking R to read your bullshit\n",
    "%cd {raw_data_location}\n",
    "# !gunzip *.gz\n",
    "\n",
    "# Used R to convert to sparse matrix format, since matrix was totally unfiltered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason python lacks good facilities for loading COO sparse matrices, so whatever, let's do this manually \n",
    "\n",
    "sparse_c_e = np.loadtxt('mtx.mtx')\n",
    "rows = np.max(sparse_c_e[:,0])\n",
    "columns = np.max(sparse_c_e[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"rows:{rows},columns:{columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note one extra row because the R mtx summary indexes from 1\n",
    "from scipy.sparse import coo_matrix\n",
    "sparse_c_e_np = coo_matrix((sparse_c_e[:,2],(sparse_c_e[:,0].astype(dtype=int),sparse_c_e[:,1].astype(dtype=int))),shape=(int(rows+1),int(columns+1)),dtype=float)\n",
    "sparse_c_e_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conveniently we didn't omit the header from the R row names, so it actually matches the matrix above\n",
    "header = np.loadtxt('raw_header.txt',dtype='str')\n",
    "header = header[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,element in enumerate(header):\n",
    "    header[i] = element.strip('\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All cells have at least one read\n",
    "np.sum(np.sum(sparse_c_e_np,axis=0) > 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First select fatures that have at least one read\n",
    "feature_mask = np.sum(sparse_c_e_np,axis=1) > 10\n",
    "feature_mask = np.array(feature_mask).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(feature_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to operate on rows, we'll need to convert this to a CSR\n",
    "feature_filtered = sparse_c_e_np.tocsr()[feature_mask[1:]]\n",
    "filtered_header = header[feature_mask[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to examine the distribution of per-cell read sums\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(np.array(np.sum(feature_filtered,axis=0)).flatten(),bins=np.arange(0,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.sum(feature_filtered,axis=0) > 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a substantial number of cells showing at least 1000 UMIs (~30%), so we could simply choose these to operate on (at least for the moment)\n",
    "cell_filter = np.array(np.sum(feature_filtered,axis=0) > 1000).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_filtered = feature_filtered.T[cell_filter].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_filtered = double_filtered.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our matrix is still sort of porky to be operated on directly. Before we begin filtering by variance however, we should normalize by size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(np.array(np.sum(double_filtered,axis=1)).flatten(),bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_sums = np.array(np.sum(double_filtered,axis=1)).ravel()\n",
    "cell_sums.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_corrected = (double_filtered / np.tile(cell_sums,(double_filtered.shape[1],1)).T) * 1000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.hist(np.array(np.sum(size_corrected,axis=1)).flatten(),bins=50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.hist(np.array(size_corrected).flatten(),bins=np.arange(0,1000,50),log=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_size_corrected = np.log10(1 + size_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.array(np.mean(log_size_corrected,axis=0)).ravel()\n",
    "variances = np.array(np.var(log_size_corrected,axis=0)).ravel()\n",
    "\n",
    "mean_sort = np.argsort(means)\n",
    "var_sort = np.argsort(variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Mean Vs Variance, Log10(n+1) TPM\")\n",
    "plt.scatter(means,variances,s=1)\n",
    "plt.xlabel(\"Mean\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Variance by mean rank, Log10(n+1) TPM\")\n",
    "plt.scatter(np.arange(len(mean_sort)),variances[mean_sort],s=1,c='blue')\n",
    "plt.scatter(np.arange(len(mean_sort)),means[mean_sort],s=1,c='red')\n",
    "plt.xlabel(\"Mean\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Variance by mean rank, Log10(n+1) TPM\")\n",
    "plt.scatter(np.arange(10000,len(mean_sort)),variances[mean_sort[10000:]],s=1,c='blue')\n",
    "plt.scatter(np.arange(10000,len(mean_sort)),means[mean_sort[10000:]],s=1,c='red')\n",
    "plt.xlabel(\"Mean\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Ranked Variance, Log10(n+1) TPM\")\n",
    "plt.scatter(np.arange(len(var_sort)),variances[var_sort],s=1)\n",
    "plt.scatter(np.arange(len(var_sort)),means[var_sort],s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = variances/means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Cov by ranked mean, Log10(n+1) TPM\")\n",
    "plt.scatter(np.arange(len(mean_sort[10000:])),cov[mean_sort[10000:]],s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Cov by ranked mean, Log10(n+1) TPM\")\n",
    "plt.scatter(np.arange(len(var_sort[10000:])),cov[var_sort[10000:]],s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may want to keep top 5000 genes by variance, this is a pretty diverse dataset\n",
    "\n",
    "umis = double_filtered.T[var_sort[-5000:]].T\n",
    "umis = umis.todense()\n",
    "counts = log_size_corrected.T[var_sort[-5000:]].T\n",
    "header = filtered_header[var_sort[-5000:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umis = np.array(umis)\n",
    "counts = np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(raw_data_location+\"umis.tsv\",umis)\n",
    "np.savetxt(raw_data_location+\"counts.tsv\",counts)\n",
    "np.savetxt(raw_data_location+\"header.txt\",header,fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh {raw_data_location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "umis = np.loadtxt(raw_data_location+\"umis.tsv\")\n",
    "counts = np.loadtxt(raw_data_location+\"counts.tsv\")\n",
    "header = np.loadtxt(raw_data_location+\"header.txt\",dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counts.shape)\n",
    "print(umis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/localscratch/bbrener1/rusty_forest_v3/work\n"
     ]
    }
   ],
   "source": [
    "%cd /localscratch/bbrener1/rusty_forest_v3/work/\n",
    "import sys\n",
    "sys.path.append(\"/localscratch/bbrener1/rusty_forest_v3/src/\")\n",
    "import lumberjack\n",
    "import tree_reader as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_counts = PCA(n_components=50).fit_transform(counts)\n",
    "print(pca_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting context\n",
      "Input:(10566, 5000)\n",
      "Output:(10566, 5000)\n",
      "Generating trees\n",
      "Running /localscratch/bbrener1/rusty_forest_v3/target/release/rusty_lumberjack_v3\n",
      "Command: /localscratch/bbrener1/rusty_forest_v3/target/release/rusty_lumberjack_v3 -ic /tmp/tmp2r4w0c9b/input.counts -oc /tmp/tmp2r4w0c9b/output.counts -o /tmp/tmp2r4w0c9b/tmp -auto -ifh /tmp/tmp2r4w0c9b/tmp.ifh -ofh /tmp/tmp2r4w0c9b/tmp.ofh -ifs 1500 -ofs 1500 -ss 1000 -sfr 0.5 -trees 100 -leaves 100 -depth 10\n",
      "Read matrix:(10566, 5000)\n",
      "Read matrix:(10566, 5000)\n",
      "Reading header: /tmp/tmp2r4w0c9b/tmp.ifh\n",
      "Read 5000 lines\n",
      "Reading header: /tmp/tmp2r4w0c9b/tmp.ofh\n",
      "Read 5000 lines\n",
      "Read parameters\n",
      "Starting loop\n",
      "Computing tree 93\n",
      "Computing tree 4\n",
      "Computing tree 38\n",
      "Computing tree 45\n",
      "Computing tree 15\n",
      "Computing tree 0\n",
      "Computing tree 80\n",
      "Computing tree 76\n",
      "Computing tree 63\n",
      "Computing tree 84\n",
      "Computing tree 69\n",
      "Computing tree 70\n",
      "Computing tree 98\n",
      "Computing tree 24\n",
      "Computing tree 26\n",
      "Computing tree 65\n",
      "Computing tree 82\n",
      "Computing tree 78\n",
      "Computing tree 31\n",
      "Computing tree 50\n",
      "Computing tree 8\n",
      "Computing tree 99\n",
      "Computing tree 68\n",
      "Computing tree 32\n",
      "Computing tree 22\n",
      "Computing tree 56\n",
      "Computing tree 19\n",
      "Computing tree 2\n",
      "Computing tree 37\n",
      "Computing tree 77\n",
      "Computing tree 94\n",
      "Computing tree 60\n",
      "Computing tree 59\n",
      "Computing tree 62\n",
      "Computing tree 28\n",
      "Computing tree 3\n",
      "Computing tree 34\n",
      "Computing tree 49\n",
      "Computing tree 81\n",
      "Computing tree 72\n",
      "Computing tree 85\n",
      "Computing tree 30\n",
      "Computing tree 61\n",
      "Computing tree 1\n",
      "Computing tree 96\n",
      "Computing tree 83\n",
      "Computing tree 9\n",
      "Computing tree 23\n",
      "Computing tree 11\n",
      "Computing tree 41\n",
      "Computing tree 86\n",
      "Computing tree 57\n",
      "Computing tree 10\n",
      "Computing tree 43\n",
      "Computing tree 40\n",
      "Computing tree 44\n",
      "Computing tree 25\n",
      "Computing tree 79\n",
      "Computing tree 75\n",
      "Computing tree 18\n",
      "Computing tree 67\n",
      "Computing tree 12\n",
      "Computing tree 14\n",
      "Computing tree 87\n",
      "Computing tree 47\n",
      "Computing tree 64\n",
      "Computing tree 7\n",
      "Computing tree 46\n",
      "Computing tree 35\n",
      "Computing tree 6\n",
      "Computing tree 88\n",
      "Computing tree 5\n",
      "Computing tree 13\n",
      "Computing tree 71\n",
      "Computing tree 16\n",
      "Computing tree 21\n",
      "Computing tree 66\n",
      "Computing tree 90\n",
      "Computing tree 73\n",
      "Computing tree 55\n",
      "Computing tree 53\n",
      "Computing tree 20\n",
      "Computing tree 48\n",
      "Computing tree 42\n",
      "Computing tree 17\n",
      "Computing tree 97\n",
      "Computing tree 36\n",
      "Computing tree 52\n",
      "Computing tree 58\n",
      "Computing tree 74\n",
      "Computing tree 95\n",
      "Computing tree 29\n",
      "Computing tree 54\n",
      "Computing tree 51\n",
      "Computing tree 27\n",
      "Computing tree 89\n",
      "Computing tree 33\n",
      "Computing tree 92\n",
      "Computing tree 39\n",
      "Computing tree 91\n"
     ]
    }
   ],
   "source": [
    "forest = lumberjack.fit(\n",
    "    counts,\n",
    "    header=header,\n",
    "    ifs=1500,\n",
    "    ofs=1500,\n",
    "    ss=1000,\n",
    "#     dispersion_mode='ssme',\n",
    "    sfr=0.5,\n",
    "#     norm='l2',\n",
    "    trees=100,\n",
    "    leaves=100,\n",
    "    depth=10,\n",
    "#     lrg_mem=True\n",
    ")\n",
    "\n",
    "# forest = lumberjack.fit(\n",
    "#     input_counts=umis,\n",
    "#     output_counts=umis,\n",
    "#     ifh=None,\n",
    "#     ofh=None,\n",
    "#     ifs=2000,\n",
    "#     ofs=2000,\n",
    "#     ss=1000,\n",
    "# #     dispersion_mode='ssme',\n",
    "#     sfr=.5,\n",
    "# #     norm='l2',\n",
    "#     trees=100,\n",
    "#     depth=10,\n",
    "#     leaves=100,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.backup(\"c_elegans_forest\")\n",
    "forest.backup(\"c_elegans_forest_reduced_cache\")\n",
    "# forest.backup(\"c_elegans_forest_pca\")\n",
    "# forest.backup(\"c_elegans_forest_pca_cache\")\n",
    "# forest.backup(\"c_elegans_forest_double_pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = tr.Forest.reconstitute('c_elegans_forest_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.reset_sample_clusters()\n",
    "# forest.cluster_samples_encoding(sub=.8,k=30,metric=\"cosine\",pca=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.reset_leaf_clusters()\n",
    "forest.cluster_leaves_samples(sub=.5,k=30,metric=\"cosine\",pca=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.cluster_samples_leaf_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest.tsne(pca=100)\n",
    "forest.plot_sample_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = forest.coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(coordinates[:,0],coordinates[:,1],c=forest.sample_labels == 38,s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.sample_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.set_cache(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
